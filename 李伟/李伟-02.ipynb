{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bao2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P4jvE9YgP1B",
        "outputId": "59bee3a4-082b-4d4d-db7b-cc83578c128e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -r /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 2)) (4.41.1)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->-r /content/drive/My Drive/bao_03/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (50.3.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu_uHjzSkbsY",
        "outputId": "547edba8-baa5-4a4d-cbb7-a24d92b626f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model TextCNN"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:05, 35863.21it/s]\n",
            "10000it [00:00, 12040.77it/s]\n",
            "10000it [00:00, 11560.05it/s]\n",
            "Time usage: 0:00:07\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))\n",
            "    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))\n",
            "    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=768, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc: 14.06%,  Val Loss:   2.7,  Val Acc: 13.37%,  Time: 0:00:01 *\n",
            "Iter:    100,  Train Loss:  0.76,  Train Acc: 71.88%,  Val Loss:  0.69,  Val Acc: 78.41%,  Time: 0:00:04 *\n",
            "Iter:    200,  Train Loss:  0.72,  Train Acc: 72.66%,  Val Loss:  0.55,  Val Acc: 83.27%,  Time: 0:00:07 *\n",
            "Iter:    300,  Train Loss:  0.42,  Train Acc: 84.38%,  Val Loss:  0.49,  Val Acc: 84.89%,  Time: 0:00:10 *\n",
            "Iter:    400,  Train Loss:  0.72,  Train Acc: 78.12%,  Val Loss:  0.47,  Val Acc: 85.41%,  Time: 0:00:13 *\n",
            "Iter:    500,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.44,  Val Acc: 86.23%,  Time: 0:00:16 *\n",
            "Iter:    600,  Train Loss:  0.52,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 86.78%,  Time: 0:00:19 *\n",
            "Iter:    700,  Train Loss:  0.46,  Train Acc: 86.72%,  Val Loss:   0.4,  Val Acc: 87.41%,  Time: 0:00:22 *\n",
            "Iter:    800,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 87.78%,  Time: 0:00:25 *\n",
            "Iter:    900,  Train Loss:  0.48,  Train Acc: 87.50%,  Val Loss:  0.38,  Val Acc: 88.25%,  Time: 0:00:28 *\n",
            "Iter:   1000,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 88.05%,  Time: 0:00:31 *\n",
            "Iter:   1100,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 88.34%,  Time: 0:00:34 *\n",
            "Iter:   1200,  Train Loss:   0.4,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 89.03%,  Time: 0:00:37 *\n",
            "Iter:   1300,  Train Loss:  0.43,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.59%,  Time: 0:00:40 *\n",
            "Iter:   1400,  Train Loss:  0.54,  Train Acc: 84.38%,  Val Loss:  0.35,  Val Acc: 89.04%,  Time: 0:00:43 *\n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.41,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.85%,  Time: 0:00:46 \n",
            "Iter:   1600,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 89.19%,  Time: 0:00:49 *\n",
            "Iter:   1700,  Train Loss:  0.41,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 89.37%,  Time: 0:00:52 \n",
            "Iter:   1800,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 89.11%,  Time: 0:00:55 \n",
            "Iter:   1900,  Train Loss:  0.38,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.38%,  Time: 0:00:57 *\n",
            "Iter:   2000,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.49%,  Time: 0:01:00 *\n",
            "Iter:   2100,  Train Loss:  0.41,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.44%,  Time: 0:01:03 \n",
            "Iter:   2200,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.46%,  Time: 0:01:06 *\n",
            "Iter:   2300,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.72%,  Time: 0:01:09 *\n",
            "Iter:   2400,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.98%,  Time: 0:01:12 *\n",
            "Iter:   2500,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 89.99%,  Time: 0:01:15 *\n",
            "Iter:   2600,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.74%,  Time: 0:01:18 \n",
            "Iter:   2700,  Train Loss:  0.18,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:01:21 \n",
            "Iter:   2800,  Train Loss:   0.4,  Train Acc: 85.16%,  Val Loss:  0.33,  Val Acc: 89.68%,  Time: 0:01:24 \n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.74%,  Time: 0:01:27 \n",
            "Iter:   3000,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.91%,  Time: 0:01:30 \n",
            "Iter:   3100,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 90.09%,  Time: 0:01:33 \n",
            "Iter:   3200,  Train Loss:  0.37,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.85%,  Time: 0:01:36 \n",
            "Iter:   3300,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.27%,  Time: 0:01:39 \n",
            "Iter:   3400,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 90.05%,  Time: 0:01:42 \n",
            "Iter:   3500,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 90.25%,  Time: 0:01:45 *\n",
            "Iter:   3600,  Train Loss:  0.17,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 90.13%,  Time: 0:01:48 *\n",
            "Iter:   3700,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.33,  Val Acc: 90.24%,  Time: 0:01:51 \n",
            "Iter:   3800,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.89%,  Time: 0:01:54 \n",
            "Iter:   3900,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.89%,  Time: 0:01:57 \n",
            "Iter:   4000,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.10%,  Time: 0:02:00 \n",
            "Iter:   4100,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 90.49%,  Time: 0:02:03 *\n",
            "Iter:   4200,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.10%,  Time: 0:02:06 \n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.32,  Val Acc: 90.16%,  Time: 0:02:08 \n",
            "Iter:   4400,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:  0.32,  Val Acc: 90.35%,  Time: 0:02:11 *\n",
            "Iter:   4500,  Train Loss:  0.33,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 90.14%,  Time: 0:02:14 \n",
            "Iter:   4600,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.32,  Val Acc: 90.35%,  Time: 0:02:17 \n",
            "Iter:   4700,  Train Loss:  0.47,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.16%,  Time: 0:02:20 \n",
            "Iter:   4800,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.46%,  Time: 0:02:23 \n",
            "Iter:   4900,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.59%,  Time: 0:02:26 \n",
            "Iter:   5000,  Train Loss:  0.21,  Train Acc: 96.09%,  Val Loss:  0.34,  Val Acc: 90.15%,  Time: 0:02:29 \n",
            "Iter:   5100,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 90.34%,  Time: 0:02:32 \n",
            "Iter:   5200,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.42%,  Time: 0:02:35 \n",
            "Iter:   5300,  Train Loss:   0.2,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.57%,  Time: 0:02:38 \n",
            "Iter:   5400,  Train Loss:  0.45,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.38%,  Time: 0:02:41 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:   0.3,  Test Acc: 91.02%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9230    0.8870    0.9046      1000\n",
            "       realty     0.9124    0.9370    0.9245      1000\n",
            "       stocks     0.8628    0.8550    0.8589      1000\n",
            "    education     0.9474    0.9540    0.9507      1000\n",
            "      science     0.8783    0.8590    0.8686      1000\n",
            "      society     0.8873    0.9290    0.9077      1000\n",
            "     politics     0.8965    0.8920    0.8942      1000\n",
            "       sports     0.9377    0.9630    0.9502      1000\n",
            "         game     0.9316    0.9130    0.9222      1000\n",
            "entertainment     0.9250    0.9130    0.9190      1000\n",
            "\n",
            "     accuracy                         0.9102     10000\n",
            "    macro avg     0.9102    0.9102    0.9101     10000\n",
            " weighted avg     0.9102    0.9102    0.9101     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[887  20  54   2   8  12   9   5   2   1]\n",
            " [ 10 937  16   2   3  14   7   3   2   6]\n",
            " [ 44  24 855   2  29   5  31   4   5   1]\n",
            " [  1   3   0 954   6  12   6   5   3  10]\n",
            " [  4   9  31   5 859  18  19   5  33  17]\n",
            " [  2  15   2  17  10 929  16   1   2   6]\n",
            " [  9   8  21  13  14  32 892   4   1   6]\n",
            " [  1   2   2   2   2   7   6 963   3  12]\n",
            " [  1   2   8   3  37   8   2  11 913  15]\n",
            " [  2   7   2   7  10  10   7  26  16 913]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjHUmFwIkbux",
        "outputId": "404c94c5-1672-4c21-f175-b80acaec4675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model TextRNN"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 67923.04it/s]\n",
            "10000it [00:00, 73566.47it/s]\n",
            "10000it [00:00, 40306.71it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/10]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc:  7.81%,  Val Loss:   2.3,  Val Acc: 10.01%,  Time: 0:00:02 *\n",
            "Iter:    100,  Train Loss:   1.6,  Train Acc: 42.97%,  Val Loss:   1.6,  Val Acc: 38.17%,  Time: 0:00:04 *\n",
            "Iter:    200,  Train Loss:   1.4,  Train Acc: 53.12%,  Val Loss:   1.2,  Val Acc: 55.74%,  Time: 0:00:06 *\n",
            "Iter:    300,  Train Loss:  0.87,  Train Acc: 71.88%,  Val Loss:  0.94,  Val Acc: 68.16%,  Time: 0:00:07 *\n",
            "Iter:    400,  Train Loss:   0.8,  Train Acc: 73.44%,  Val Loss:  0.72,  Val Acc: 77.86%,  Time: 0:00:09 *\n",
            "Iter:    500,  Train Loss:  0.57,  Train Acc: 81.25%,  Val Loss:  0.61,  Val Acc: 81.32%,  Time: 0:00:11 *\n",
            "Iter:    600,  Train Loss:  0.54,  Train Acc: 82.81%,  Val Loss:  0.54,  Val Acc: 83.04%,  Time: 0:00:13 *\n",
            "Iter:    700,  Train Loss:  0.46,  Train Acc: 85.16%,  Val Loss:   0.5,  Val Acc: 83.97%,  Time: 0:00:15 *\n",
            "Iter:    800,  Train Loss:   0.5,  Train Acc: 85.94%,  Val Loss:  0.48,  Val Acc: 85.16%,  Time: 0:00:17 *\n",
            "Iter:    900,  Train Loss:  0.49,  Train Acc: 87.50%,  Val Loss:  0.45,  Val Acc: 86.13%,  Time: 0:00:18 *\n",
            "Iter:   1000,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.45,  Val Acc: 85.65%,  Time: 0:00:20 \n",
            "Iter:   1100,  Train Loss:  0.32,  Train Acc: 91.41%,  Val Loss:  0.42,  Val Acc: 86.64%,  Time: 0:00:22 *\n",
            "Iter:   1200,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.42,  Val Acc: 87.03%,  Time: 0:00:24 *\n",
            "Iter:   1300,  Train Loss:  0.42,  Train Acc: 86.72%,  Val Loss:  0.42,  Val Acc: 86.97%,  Time: 0:00:26 *\n",
            "Iter:   1400,  Train Loss:  0.51,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 86.96%,  Time: 0:00:28 *\n",
            "Epoch [2/10]\n",
            "Iter:   1500,  Train Loss:  0.43,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 87.51%,  Time: 0:00:29 *\n",
            "Iter:   1600,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 87.30%,  Time: 0:00:31 \n",
            "Iter:   1700,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.38,  Val Acc: 88.08%,  Time: 0:00:33 *\n",
            "Iter:   1800,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 88.17%,  Time: 0:00:35 \n",
            "Iter:   1900,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 88.84%,  Time: 0:00:37 *\n",
            "Iter:   2000,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 88.60%,  Time: 0:00:39 *\n",
            "Iter:   2100,  Train Loss:  0.36,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.79%,  Time: 0:00:40 \n",
            "Iter:   2200,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 89.04%,  Time: 0:00:42 \n",
            "Iter:   2300,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.22%,  Time: 0:00:44 *\n",
            "Iter:   2400,  Train Loss:  0.23,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 88.89%,  Time: 0:00:46 \n",
            "Iter:   2500,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.25%,  Time: 0:00:48 \n",
            "Iter:   2600,  Train Loss:  0.33,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:00:49 \n",
            "Iter:   2700,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 88.58%,  Time: 0:00:51 \n",
            "Iter:   2800,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:00:53 *\n",
            "Epoch [3/10]\n",
            "Iter:   2900,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.74%,  Time: 0:00:55 *\n",
            "Iter:   3000,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.73%,  Time: 0:00:57 \n",
            "Iter:   3100,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.51%,  Time: 0:00:58 \n",
            "Iter:   3200,  Train Loss:  0.35,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.14%,  Time: 0:01:00 \n",
            "Iter:   3300,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.79%,  Time: 0:01:02 *\n",
            "Iter:   3400,  Train Loss:  0.23,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.81%,  Time: 0:01:04 \n",
            "Iter:   3500,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.47%,  Time: 0:01:06 \n",
            "Iter:   3600,  Train Loss:  0.19,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 89.84%,  Time: 0:01:07 *\n",
            "Iter:   3700,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.50%,  Time: 0:01:09 \n",
            "Iter:   3800,  Train Loss:  0.29,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 89.82%,  Time: 0:01:11 *\n",
            "Iter:   3900,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.11%,  Time: 0:01:13 \n",
            "Iter:   4000,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.32,  Val Acc: 89.97%,  Time: 0:01:15 \n",
            "Iter:   4100,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.07%,  Time: 0:01:16 \n",
            "Iter:   4200,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.03%,  Time: 0:01:18 \n",
            "Epoch [4/10]\n",
            "Iter:   4300,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.00%,  Time: 0:01:20 \n",
            "Iter:   4400,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.31,  Val Acc: 90.28%,  Time: 0:01:22 *\n",
            "Iter:   4500,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.78%,  Time: 0:01:24 \n",
            "Iter:   4600,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.25%,  Time: 0:01:26 \n",
            "Iter:   4700,  Train Loss:  0.32,  Train Acc: 87.50%,  Val Loss:  0.29,  Val Acc: 90.75%,  Time: 0:01:27 *\n",
            "Iter:   4800,  Train Loss:  0.12,  Train Acc: 96.09%,  Val Loss:   0.3,  Val Acc: 90.66%,  Time: 0:01:29 \n",
            "Iter:   4900,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.24%,  Time: 0:01:31 \n",
            "Iter:   5000,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.73%,  Time: 0:01:33 \n",
            "Iter:   5100,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.14%,  Time: 0:01:35 \n",
            "Iter:   5200,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.47%,  Time: 0:01:36 \n",
            "Iter:   5300,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.44%,  Time: 0:01:38 \n",
            "Iter:   5400,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 90.79%,  Time: 0:01:40 \n",
            "Iter:   5500,  Train Loss:  0.24,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.56%,  Time: 0:01:42 \n",
            "Iter:   5600,  Train Loss:  0.14,  Train Acc: 95.31%,  Val Loss:  0.31,  Val Acc: 90.36%,  Time: 0:01:44 \n",
            "Epoch [5/10]\n",
            "Iter:   5700,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.48%,  Time: 0:01:45 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.29,  Test Acc: 90.62%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.8928    0.9080    0.9003      1000\n",
            "       realty     0.8951    0.9300    0.9122      1000\n",
            "       stocks     0.8735    0.8080    0.8395      1000\n",
            "    education     0.9434    0.9500    0.9467      1000\n",
            "      science     0.8421    0.8530    0.8475      1000\n",
            "      society     0.8887    0.9100    0.8992      1000\n",
            "     politics     0.8785    0.8820    0.8802      1000\n",
            "       sports     0.9827    0.9650    0.9738      1000\n",
            "         game     0.9370    0.9220    0.9294      1000\n",
            "entertainment     0.9294    0.9340    0.9317      1000\n",
            "\n",
            "     accuracy                         0.9062     10000\n",
            "    macro avg     0.9063    0.9062    0.9061     10000\n",
            " weighted avg     0.9063    0.9062    0.9061     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[908  22  34   6   7  11   8   1   0   3]\n",
            " [ 12 930  12   2   7  13   6   3   5  10]\n",
            " [ 65  37 808   3  43   4  34   1   4   1]\n",
            " [  0   2   5 950   8  16  11   0   0   8]\n",
            " [ 10   8  30   8 853  19  22   0  36  14]\n",
            " [  3  19   2  17  11 910  22   0   3  13]\n",
            " [ 10   8  21   7  27  35 882   1   5   4]\n",
            " [  1   1   3   2   3   4   8 965   0  13]\n",
            " [  3   3   7   5  42   6   5   2 922   5]\n",
            " [  5   9   3   7  12   6   6   9   9 934]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bY_BcAfy89U",
        "outputId": "bc3f7d3e-bcb3-4733-b925-b597f9b9bc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model TextRNN_Att"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 70335.01it/s]\n",
            "10000it [00:00, 77680.78it/s]\n",
            "10000it [00:00, 40611.75it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (tanh1): Tanh()\n",
            "  (tanh2): Tanh()\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/10]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc:  6.25%,  Val Loss:   2.3,  Val Acc: 10.04%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:   0.7,  Train Acc: 79.69%,  Val Loss:  0.77,  Val Acc: 73.96%,  Time: 0:00:03 *\n",
            "Iter:    200,  Train Loss:   0.8,  Train Acc: 75.78%,  Val Loss:   0.6,  Val Acc: 80.61%,  Time: 0:00:05 *\n",
            "Iter:    300,  Train Loss:  0.41,  Train Acc: 86.72%,  Val Loss:  0.51,  Val Acc: 83.66%,  Time: 0:00:06 *\n",
            "Iter:    400,  Train Loss:   0.5,  Train Acc: 85.16%,  Val Loss:  0.48,  Val Acc: 84.89%,  Time: 0:00:08 *\n",
            "Iter:    500,  Train Loss:  0.41,  Train Acc: 86.72%,  Val Loss:  0.45,  Val Acc: 85.46%,  Time: 0:00:10 *\n",
            "Iter:    600,  Train Loss:  0.46,  Train Acc: 83.59%,  Val Loss:  0.42,  Val Acc: 86.71%,  Time: 0:00:12 *\n",
            "Iter:    700,  Train Loss:  0.39,  Train Acc: 88.28%,  Val Loss:  0.42,  Val Acc: 86.36%,  Time: 0:00:14 *\n",
            "Iter:    800,  Train Loss:  0.32,  Train Acc: 91.41%,  Val Loss:  0.38,  Val Acc: 87.63%,  Time: 0:00:16 *\n",
            "Iter:    900,  Train Loss:  0.45,  Train Acc: 87.50%,  Val Loss:  0.38,  Val Acc: 87.79%,  Time: 0:00:18 *\n",
            "Iter:   1000,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 87.99%,  Time: 0:00:20 *\n",
            "Iter:   1100,  Train Loss:  0.28,  Train Acc: 92.19%,  Val Loss:  0.38,  Val Acc: 87.63%,  Time: 0:00:22 \n",
            "Iter:   1200,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 88.37%,  Time: 0:00:24 *\n",
            "Iter:   1300,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.56%,  Time: 0:00:26 \n",
            "Iter:   1400,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.67%,  Time: 0:00:28 *\n",
            "Epoch [2/10]\n",
            "Iter:   1500,  Train Loss:  0.41,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.37%,  Time: 0:00:30 \n",
            "Iter:   1600,  Train Loss:  0.34,  Train Acc: 85.16%,  Val Loss:  0.38,  Val Acc: 88.25%,  Time: 0:00:31 \n",
            "Iter:   1700,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 88.42%,  Time: 0:00:33 \n",
            "Iter:   1800,  Train Loss:  0.26,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.88%,  Time: 0:00:35 *\n",
            "Iter:   1900,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.52%,  Time: 0:00:37 *\n",
            "Iter:   2000,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 88.93%,  Time: 0:00:39 \n",
            "Iter:   2100,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.41%,  Time: 0:00:41 \n",
            "Iter:   2200,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.58%,  Time: 0:00:43 \n",
            "Iter:   2300,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 89.67%,  Time: 0:00:45 *\n",
            "Iter:   2400,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.09%,  Time: 0:00:47 \n",
            "Iter:   2500,  Train Loss:  0.23,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.49%,  Time: 0:00:49 \n",
            "Iter:   2600,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.74%,  Time: 0:00:51 \n",
            "Iter:   2700,  Train Loss:  0.28,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 89.95%,  Time: 0:00:53 *\n",
            "Iter:   2800,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 89.77%,  Time: 0:00:55 \n",
            "Epoch [3/10]\n",
            "Iter:   2900,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.95%,  Time: 0:00:56 \n",
            "Iter:   3000,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.67%,  Time: 0:00:58 \n",
            "Iter:   3100,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.34,  Val Acc: 89.21%,  Time: 0:01:00 \n",
            "Iter:   3200,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.58%,  Time: 0:01:02 \n",
            "Iter:   3300,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 89.99%,  Time: 0:01:04 \n",
            "Iter:   3400,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.32,  Val Acc: 89.79%,  Time: 0:01:06 \n",
            "Iter:   3500,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.34,  Val Acc: 89.61%,  Time: 0:01:08 \n",
            "Iter:   3600,  Train Loss:  0.15,  Train Acc: 95.31%,  Val Loss:  0.32,  Val Acc: 90.05%,  Time: 0:01:10 \n",
            "Iter:   3700,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.17%,  Time: 0:01:12 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:   0.3,  Test Acc: 90.09%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9073    0.8710    0.8888      1000\n",
            "       realty     0.9124    0.9170    0.9147      1000\n",
            "       stocks     0.8723    0.7720    0.8191      1000\n",
            "    education     0.9652    0.9150    0.9394      1000\n",
            "      science     0.8188    0.8720    0.8446      1000\n",
            "      society     0.8690    0.9290    0.8980      1000\n",
            "     politics     0.8788    0.8850    0.8819      1000\n",
            "       sports     0.9798    0.9690    0.9744      1000\n",
            "         game     0.9348    0.9170    0.9258      1000\n",
            "entertainment     0.8818    0.9620    0.9201      1000\n",
            "\n",
            "     accuracy                         0.9009     10000\n",
            "    macro avg     0.9020    0.9009    0.9007     10000\n",
            " weighted avg     0.9020    0.9009    0.9007     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[871  23  50   5  19  10  10   2   3   7]\n",
            " [  8 917  17   0   8  17   9   3   4  17]\n",
            " [ 62  32 772   0  77   3  42   1   9   2]\n",
            " [  0   3   4 915   7  37  11   2   4  17]\n",
            " [  8   6  12   6 872  19  22   5  28  22]\n",
            " [  0   9   2  10   7 929  19   1   4  19]\n",
            " [  5   7  21   9  15  36 885   1   5  16]\n",
            " [  0   1   2   1   0   5   3 969   0  19]\n",
            " [  3   2   3   1  53   5   5   1 917  10]\n",
            " [  3   5   2   1   7   8   1   4   7 962]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuaLmxK_0Xch",
        "outputId": "da0976c0-cb0a-47c2-fc53-639c8d43330d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model TextRCNN"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 67607.44it/s]\n",
            "10000it [00:00, 77289.14it/s]\n",
            "10000it [00:00, 40909.90it/s]\n",
            "Time usage: 0:00:03\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.0 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (lstm): LSTM(300, 256, batch_first=True, dropout=1.0, bidirectional=True)\n",
            "  (maxpool): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): Linear(in_features=812, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/10]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc: 12.50%,  Val Loss:   2.4,  Val Acc: 13.97%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:  0.68,  Train Acc: 69.53%,  Val Loss:  0.71,  Val Acc: 76.68%,  Time: 0:00:02 *\n",
            "Iter:    200,  Train Loss:  0.63,  Train Acc: 81.25%,  Val Loss:  0.58,  Val Acc: 81.95%,  Time: 0:00:03 *\n",
            "Iter:    300,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.49,  Val Acc: 84.76%,  Time: 0:00:04 *\n",
            "Iter:    400,  Train Loss:  0.57,  Train Acc: 82.03%,  Val Loss:  0.45,  Val Acc: 85.83%,  Time: 0:00:05 *\n",
            "Iter:    500,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.43,  Val Acc: 86.58%,  Time: 0:00:07 *\n",
            "Iter:    600,  Train Loss:  0.42,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 86.79%,  Time: 0:00:08 *\n",
            "Iter:    700,  Train Loss:  0.36,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.13%,  Time: 0:00:09 *\n",
            "Iter:    800,  Train Loss:  0.32,  Train Acc: 92.19%,  Val Loss:  0.37,  Val Acc: 88.18%,  Time: 0:00:11 *\n",
            "Iter:    900,  Train Loss:   0.4,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.49%,  Time: 0:00:12 *\n",
            "Iter:   1000,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.64%,  Time: 0:00:13 *\n",
            "Iter:   1100,  Train Loss:  0.26,  Train Acc: 93.75%,  Val Loss:  0.37,  Val Acc: 88.30%,  Time: 0:00:14 \n",
            "Iter:   1200,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 88.93%,  Time: 0:00:16 *\n",
            "Iter:   1300,  Train Loss:  0.31,  Train Acc: 85.94%,  Val Loss:  0.34,  Val Acc: 88.98%,  Time: 0:00:17 *\n",
            "Iter:   1400,  Train Loss:  0.42,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.04%,  Time: 0:00:18 *\n",
            "Epoch [2/10]\n",
            "Iter:   1500,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.23%,  Time: 0:00:19 *\n",
            "Iter:   1600,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.07%,  Time: 0:00:21 \n",
            "Iter:   1700,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.64%,  Time: 0:00:22 \n",
            "Iter:   1800,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.06%,  Time: 0:00:23 *\n",
            "Iter:   1900,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.03%,  Time: 0:00:24 *\n",
            "Iter:   2000,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.31,  Val Acc: 90.06%,  Time: 0:00:25 \n",
            "Iter:   2100,  Train Loss:   0.3,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 89.92%,  Time: 0:00:27 \n",
            "Iter:   2200,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.24%,  Time: 0:00:28 *\n",
            "Iter:   2300,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 90.34%,  Time: 0:00:29 *\n",
            "Iter:   2400,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 89.75%,  Time: 0:00:30 \n",
            "Iter:   2500,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 89.89%,  Time: 0:00:32 \n",
            "Iter:   2600,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.28%,  Time: 0:00:33 \n",
            "Iter:   2700,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.18%,  Time: 0:00:34 \n",
            "Iter:   2800,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 90.46%,  Time: 0:00:35 \n",
            "Epoch [3/10]\n",
            "Iter:   2900,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.29,  Val Acc: 90.80%,  Time: 0:00:36 \n",
            "Iter:   3000,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:   0.3,  Val Acc: 90.29%,  Time: 0:00:38 \n",
            "Iter:   3100,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.31,  Val Acc: 90.05%,  Time: 0:00:39 \n",
            "Iter:   3200,  Train Loss:  0.32,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.23%,  Time: 0:00:40 \n",
            "Iter:   3300,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 90.30%,  Time: 0:00:41 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.28,  Test Acc: 90.83%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.8925    0.9050    0.8987      1000\n",
            "       realty     0.8771    0.9490    0.9116      1000\n",
            "       stocks     0.8727    0.8160    0.8434      1000\n",
            "    education     0.9562    0.9390    0.9475      1000\n",
            "      science     0.8825    0.8190    0.8496      1000\n",
            "      society     0.8895    0.9260    0.9074      1000\n",
            "     politics     0.8865    0.8830    0.8848      1000\n",
            "       sports     0.9838    0.9720    0.9779      1000\n",
            "         game     0.9296    0.9250    0.9273      1000\n",
            "entertainment     0.9134    0.9490    0.9308      1000\n",
            "\n",
            "     accuracy                         0.9083     10000\n",
            "    macro avg     0.9084    0.9083    0.9079     10000\n",
            " weighted avg     0.9084    0.9083    0.9079     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[905  25  37   4   6   9   8   1   2   3]\n",
            " [ 10 949  12   0   6  12   3   1   0   7]\n",
            " [ 65  39 816   0  32   1  36   0   8   3]\n",
            " [  2   5   2 939   7  17   7   1   6  14]\n",
            " [ 13  14  36   6 819  22  22   5  39  24]\n",
            " [  1  19   0  17   4 926  19   0   3  11]\n",
            " [ 12  16  20  11  15  32 883   1   3   7]\n",
            " [  0   2   1   0   1   6   5 972   0  13]\n",
            " [  2   7   8   0  33   9   6   2 925   8]\n",
            " [  4   6   3   5   5   7   7   5   9 949]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL6IJ-4J0XhP",
        "outputId": "634646e7-9fdc-40a6-8494-8246ecb04360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model FastText --embedding random "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:09, 19488.32it/s]\n",
            "10000it [00:00, 21187.20it/s]\n",
            "10000it [00:00, 21555.08it/s]\n",
            "Time usage: 0:00:10\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300, padding_idx=4761)\n",
            "  (embedding_ngram2): Embedding(250499, 300)\n",
            "  (embedding_ngram3): Embedding(250499, 300)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=900, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.6,  Train Acc:  7.03%,  Val Loss:   2.3,  Val Acc:  9.65%,  Time: 0:00:03 *\n",
            "Iter:    100,  Train Loss:   1.2,  Train Acc: 61.72%,  Val Loss:   1.0,  Val Acc: 69.68%,  Time: 0:00:09 *\n",
            "Iter:    200,  Train Loss:   1.2,  Train Acc: 62.50%,  Val Loss:  0.76,  Val Acc: 76.23%,  Time: 0:00:15 *\n",
            "Iter:    300,  Train Loss:  0.78,  Train Acc: 77.34%,  Val Loss:  0.69,  Val Acc: 77.41%,  Time: 0:00:29 *\n",
            "Iter:    400,  Train Loss:  0.81,  Train Acc: 77.34%,  Val Loss:  0.63,  Val Acc: 79.21%,  Time: 0:00:45 *\n",
            "Iter:    500,  Train Loss:  0.66,  Train Acc: 81.25%,  Val Loss:  0.58,  Val Acc: 81.39%,  Time: 0:01:01 *\n",
            "Iter:    600,  Train Loss:  0.65,  Train Acc: 78.12%,  Val Loss:  0.56,  Val Acc: 82.10%,  Time: 0:01:20 *\n",
            "Iter:    700,  Train Loss:  0.75,  Train Acc: 74.22%,  Val Loss:  0.52,  Val Acc: 83.38%,  Time: 0:01:35 *\n",
            "Iter:    800,  Train Loss:  0.67,  Train Acc: 79.69%,  Val Loss:  0.51,  Val Acc: 83.55%,  Time: 0:01:51 *\n",
            "Iter:    900,  Train Loss:   0.6,  Train Acc: 77.34%,  Val Loss:  0.48,  Val Acc: 84.53%,  Time: 0:02:06 *\n",
            "Iter:   1000,  Train Loss:  0.53,  Train Acc: 78.91%,  Val Loss:  0.47,  Val Acc: 85.04%,  Time: 0:02:20 *\n",
            "Iter:   1100,  Train Loss:  0.53,  Train Acc: 79.69%,  Val Loss:  0.46,  Val Acc: 85.12%,  Time: 0:02:34 *\n",
            "Iter:   1200,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 85.96%,  Time: 0:02:49 *\n",
            "Iter:   1300,  Train Loss:  0.56,  Train Acc: 82.81%,  Val Loss:  0.44,  Val Acc: 86.24%,  Time: 0:03:06 *\n",
            "Iter:   1400,  Train Loss:  0.64,  Train Acc: 79.69%,  Val Loss:  0.43,  Val Acc: 86.43%,  Time: 0:03:19 *\n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.62,  Train Acc: 80.47%,  Val Loss:  0.42,  Val Acc: 86.67%,  Time: 0:03:32 *\n",
            "Iter:   1600,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 87.02%,  Time: 0:03:51 *\n",
            "Iter:   1700,  Train Loss:  0.47,  Train Acc: 83.59%,  Val Loss:  0.41,  Val Acc: 87.21%,  Time: 0:04:05 *\n",
            "Iter:   1800,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 88.01%,  Time: 0:04:21 *\n",
            "Iter:   1900,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 87.99%,  Time: 0:04:35 *\n",
            "Iter:   2000,  Train Loss:  0.47,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 87.92%,  Time: 0:04:50 *\n",
            "Iter:   2100,  Train Loss:  0.43,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 88.45%,  Time: 0:05:05 *\n",
            "Iter:   2200,  Train Loss:  0.42,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.92%,  Time: 0:05:23 *\n",
            "Iter:   2300,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 89.00%,  Time: 0:05:26 \n",
            "Iter:   2400,  Train Loss:  0.46,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.66%,  Time: 0:05:29 \n",
            "Iter:   2500,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.35,  Val Acc: 89.28%,  Time: 0:05:36 *\n",
            "Iter:   2600,  Train Loss:  0.37,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 89.21%,  Time: 0:05:54 *\n",
            "Iter:   2700,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.45%,  Time: 0:06:08 *\n",
            "Iter:   2800,  Train Loss:  0.45,  Train Acc: 85.94%,  Val Loss:  0.33,  Val Acc: 89.78%,  Time: 0:06:21 *\n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.34,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.65%,  Time: 0:06:37 *\n",
            "Iter:   3000,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 89.62%,  Time: 0:06:40 \n",
            "Iter:   3100,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.81%,  Time: 0:06:55 *\n",
            "Iter:   3200,  Train Loss:  0.37,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.04%,  Time: 0:07:08 *\n",
            "Iter:   3300,  Train Loss:  0.36,  Train Acc: 86.72%,  Val Loss:  0.32,  Val Acc: 90.15%,  Time: 0:07:25 *\n",
            "Iter:   3400,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.32,  Val Acc: 90.03%,  Time: 0:07:28 \n",
            "Iter:   3500,  Train Loss:  0.18,  Train Acc: 95.31%,  Val Loss:  0.31,  Val Acc: 90.51%,  Time: 0:07:36 *\n",
            "Iter:   3600,  Train Loss:  0.15,  Train Acc: 96.88%,  Val Loss:  0.31,  Val Acc: 90.49%,  Time: 0:07:51 *\n",
            "Iter:   3700,  Train Loss:  0.32,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 90.48%,  Time: 0:08:06 *\n",
            "Iter:   3800,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.54%,  Time: 0:08:22 *\n",
            "Iter:   3900,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:   0.3,  Val Acc: 90.61%,  Time: 0:08:25 \n",
            "Iter:   4000,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:   0.3,  Val Acc: 90.48%,  Time: 0:08:28 \n",
            "Iter:   4100,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 90.84%,  Time: 0:08:37 *\n",
            "Iter:   4200,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.65%,  Time: 0:08:40 \n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:  0.22,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.93%,  Time: 0:08:55 *\n",
            "Iter:   4400,  Train Loss:  0.15,  Train Acc: 96.09%,  Val Loss:   0.3,  Val Acc: 90.97%,  Time: 0:09:09 *\n",
            "Iter:   4500,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.71%,  Time: 0:09:12 \n",
            "Iter:   4600,  Train Loss:  0.28,  Train Acc: 88.28%,  Val Loss:   0.3,  Val Acc: 90.76%,  Time: 0:09:15 \n",
            "Iter:   4700,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.28,  Val Acc: 91.44%,  Time: 0:09:22 *\n",
            "Iter:   4800,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.51%,  Time: 0:09:26 \n",
            "Iter:   4900,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.28%,  Time: 0:09:29 \n",
            "Iter:   5000,  Train Loss:  0.26,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 91.22%,  Time: 0:09:32 \n",
            "Iter:   5100,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.28,  Val Acc: 91.35%,  Time: 0:09:35 \n",
            "Iter:   5200,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.28,  Val Acc: 91.53%,  Time: 0:09:41 *\n",
            "Iter:   5300,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 91.26%,  Time: 0:09:45 \n",
            "Iter:   5400,  Train Loss:  0.42,  Train Acc: 89.84%,  Val Loss:  0.29,  Val Acc: 91.13%,  Time: 0:09:48 \n",
            "Iter:   5500,  Train Loss:  0.19,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 91.42%,  Time: 0:09:51 \n",
            "Iter:   5600,  Train Loss:  0.14,  Train Acc: 95.31%,  Val Loss:  0.27,  Val Acc: 91.77%,  Time: 0:09:58 *\n",
            "Epoch [5/20]\n",
            "Iter:   5700,  Train Loss:  0.23,  Train Acc: 96.09%,  Val Loss:  0.28,  Val Acc: 91.51%,  Time: 0:10:01 \n",
            "Iter:   5800,  Train Loss:  0.08,  Train Acc: 96.88%,  Val Loss:  0.29,  Val Acc: 91.45%,  Time: 0:10:04 \n",
            "Iter:   5900,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.65%,  Time: 0:10:07 \n",
            "Iter:   6000,  Train Loss:  0.21,  Train Acc: 89.06%,  Val Loss:  0.28,  Val Acc: 91.40%,  Time: 0:10:10 \n",
            "Iter:   6100,  Train Loss:  0.25,  Train Acc: 93.75%,  Val Loss:  0.28,  Val Acc: 91.57%,  Time: 0:10:13 \n",
            "Iter:   6200,  Train Loss:  0.11,  Train Acc: 97.66%,  Val Loss:  0.28,  Val Acc: 91.82%,  Time: 0:10:16 \n",
            "Iter:   6300,  Train Loss:   0.1,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 91.84%,  Time: 0:10:20 \n",
            "Iter:   6400,  Train Loss: 0.075,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 91.75%,  Time: 0:10:23 \n",
            "Iter:   6500,  Train Loss:  0.16,  Train Acc: 91.41%,  Val Loss:  0.28,  Val Acc: 91.84%,  Time: 0:10:26 \n",
            "Iter:   6600,  Train Loss:  0.15,  Train Acc: 92.97%,  Val Loss:  0.28,  Val Acc: 91.79%,  Time: 0:10:29 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.26,  Test Acc: 92.11%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9310    0.8910    0.9106      1000\n",
            "       realty     0.9374    0.9280    0.9327      1000\n",
            "       stocks     0.8640    0.8830    0.8734      1000\n",
            "    education     0.9437    0.9560    0.9498      1000\n",
            "      science     0.8915    0.8790    0.8852      1000\n",
            "      society     0.9086    0.9150    0.9118      1000\n",
            "     politics     0.8792    0.9100    0.8943      1000\n",
            "       sports     0.9797    0.9660    0.9728      1000\n",
            "         game     0.9495    0.9400    0.9447      1000\n",
            "entertainment     0.9300    0.9430    0.9364      1000\n",
            "\n",
            "     accuracy                         0.9211     10000\n",
            "    macro avg     0.9215    0.9211    0.9212     10000\n",
            " weighted avg     0.9215    0.9211    0.9212     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[891   9  60   5   9   9  13   1   1   2]\n",
            " [ 11 928  15   2   4  15   6   4   2  13]\n",
            " [ 38  21 883   1  20   1  29   0   5   2]\n",
            " [  1   3   2 956   4  10  11   1   2  10]\n",
            " [  4   7  28   9 879  14  21   0  25  13]\n",
            " [  1  10   3  17   8 915  29   1   6  10]\n",
            " [  7   3  24  12  16  22 910   2   1   3]\n",
            " [  0   4   1   2   3   5   6 966   0  13]\n",
            " [  1   1   5   4  32   5   6   1 940   5]\n",
            " [  3   4   1   5  11  11   4  10   8 943]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB3G2vA40Xjp",
        "outputId": "0b07a3bc-e5da-4059-d322-be3ccf8c1a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model DPCNN"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 67284.36it/s]\n",
            "10000it [00:00, 65214.92it/s]\n",
            "10000it [00:00, 40189.61it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (conv_region): Conv2d(1, 250, kernel_size=(3, 300), stride=(1, 1))\n",
            "  (conv): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (max_pool): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (padding1): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
            "  (padding2): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
            "  (relu): ReLU()\n",
            "  (fc): Linear(in_features=250, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.3,  Train Acc: 17.19%,  Val Loss:   3.9,  Val Acc: 11.92%,  Time: 0:00:00 *\n",
            "Iter:    100,  Train Loss:  0.81,  Train Acc: 71.88%,  Val Loss:  0.83,  Val Acc: 72.70%,  Time: 0:00:03 *\n",
            "Iter:    200,  Train Loss:  0.71,  Train Acc: 75.78%,  Val Loss:  0.57,  Val Acc: 81.22%,  Time: 0:00:05 *\n",
            "Iter:    300,  Train Loss:  0.45,  Train Acc: 85.16%,  Val Loss:  0.51,  Val Acc: 83.44%,  Time: 0:00:07 *\n",
            "Iter:    400,  Train Loss:  0.53,  Train Acc: 83.59%,  Val Loss:   0.5,  Val Acc: 84.00%,  Time: 0:00:10 *\n",
            "Iter:    500,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 86.23%,  Time: 0:00:12 *\n",
            "Iter:    600,  Train Loss:  0.37,  Train Acc: 91.41%,  Val Loss:  0.42,  Val Acc: 86.63%,  Time: 0:00:14 *\n",
            "Iter:    700,  Train Loss:  0.43,  Train Acc: 82.81%,  Val Loss:  0.43,  Val Acc: 86.09%,  Time: 0:00:17 \n",
            "Iter:    800,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 87.91%,  Time: 0:00:19 *\n",
            "Iter:    900,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 88.07%,  Time: 0:00:21 *\n",
            "Iter:   1000,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.38,  Val Acc: 87.89%,  Time: 0:00:24 \n",
            "Iter:   1100,  Train Loss:  0.33,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 86.72%,  Time: 0:00:26 \n",
            "Iter:   1200,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 88.43%,  Time: 0:00:28 *\n",
            "Iter:   1300,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.35,  Val Acc: 88.89%,  Time: 0:00:30 *\n",
            "Iter:   1400,  Train Loss:  0.42,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.70%,  Time: 0:00:33 \n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 88.97%,  Time: 0:00:35 *\n",
            "Iter:   1600,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 88.07%,  Time: 0:00:37 \n",
            "Iter:   1700,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 88.95%,  Time: 0:00:40 \n",
            "Iter:   1800,  Train Loss:  0.25,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:00:42 *\n",
            "Iter:   1900,  Train Loss:  0.33,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.82%,  Time: 0:00:44 *\n",
            "Iter:   2000,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.88%,  Time: 0:00:47 \n",
            "Iter:   2100,  Train Loss:  0.36,  Train Acc: 85.16%,  Val Loss:  0.31,  Val Acc: 90.10%,  Time: 0:00:49 *\n",
            "Iter:   2200,  Train Loss:  0.22,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.48%,  Time: 0:00:51 \n",
            "Iter:   2300,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.50%,  Time: 0:00:53 \n",
            "Iter:   2400,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.36,  Val Acc: 88.84%,  Time: 0:00:56 \n",
            "Iter:   2500,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.06%,  Time: 0:00:58 *\n",
            "Iter:   2600,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.84%,  Time: 0:01:00 \n",
            "Iter:   2700,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.35%,  Time: 0:01:03 \n",
            "Iter:   2800,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 89.93%,  Time: 0:01:05 \n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.32,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.90%,  Time: 0:01:07 \n",
            "Iter:   3000,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.59%,  Time: 0:01:09 *\n",
            "Iter:   3100,  Train Loss:  0.22,  Train Acc: 95.31%,  Val Loss:  0.31,  Val Acc: 89.91%,  Time: 0:01:12 \n",
            "Iter:   3200,  Train Loss:  0.35,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:14 \n",
            "Iter:   3300,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.32%,  Time: 0:01:16 \n",
            "Iter:   3400,  Train Loss:  0.23,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.47%,  Time: 0:01:18 \n",
            "Iter:   3500,  Train Loss:  0.16,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.51%,  Time: 0:01:21 \n",
            "Iter:   3600,  Train Loss:   0.1,  Train Acc: 97.66%,  Val Loss:  0.31,  Val Acc: 90.60%,  Time: 0:01:23 \n",
            "Iter:   3700,  Train Loss:  0.26,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 90.65%,  Time: 0:01:25 *\n",
            "Iter:   3800,  Train Loss:  0.25,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 89.98%,  Time: 0:01:28 \n",
            "Iter:   3900,  Train Loss:  0.19,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.44%,  Time: 0:01:30 \n",
            "Iter:   4000,  Train Loss:  0.15,  Train Acc: 96.09%,  Val Loss:  0.32,  Val Acc: 90.15%,  Time: 0:01:32 \n",
            "Iter:   4100,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.65%,  Time: 0:01:34 \n",
            "Iter:   4200,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.31,  Val Acc: 90.35%,  Time: 0:01:37 \n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:  0.31,  Val Acc: 90.43%,  Time: 0:01:39 \n",
            "Iter:   4400,  Train Loss: 0.087,  Train Acc: 96.88%,  Val Loss:   0.3,  Val Acc: 90.48%,  Time: 0:01:41 \n",
            "Iter:   4500,  Train Loss:  0.28,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.93%,  Time: 0:01:43 \n",
            "Iter:   4600,  Train Loss:  0.13,  Train Acc: 97.66%,  Val Loss:  0.29,  Val Acc: 91.12%,  Time: 0:01:46 *\n",
            "Iter:   4700,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.79%,  Time: 0:01:48 \n",
            "Iter:   4800,  Train Loss: 0.064,  Train Acc: 97.66%,  Val Loss:  0.32,  Val Acc: 90.57%,  Time: 0:01:50 \n",
            "Iter:   4900,  Train Loss:  0.12,  Train Acc: 95.31%,  Val Loss:   0.3,  Val Acc: 91.20%,  Time: 0:01:52 \n",
            "Iter:   5000,  Train Loss:  0.19,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 90.14%,  Time: 0:01:55 \n",
            "Iter:   5100,  Train Loss:  0.18,  Train Acc: 95.31%,  Val Loss:   0.3,  Val Acc: 91.04%,  Time: 0:01:57 \n",
            "Iter:   5200,  Train Loss:  0.24,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 90.27%,  Time: 0:01:59 \n",
            "Iter:   5300,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.32,  Val Acc: 90.25%,  Time: 0:02:01 \n",
            "Iter:   5400,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.68%,  Time: 0:02:04 \n",
            "Iter:   5500,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.72%,  Time: 0:02:06 \n",
            "Iter:   5600,  Train Loss: 0.087,  Train Acc: 96.09%,  Val Loss:  0.33,  Val Acc: 89.73%,  Time: 0:02:08 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.29,  Test Acc: 91.55%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9082    0.9100    0.9091      1000\n",
            "       realty     0.9340    0.9340    0.9340      1000\n",
            "       stocks     0.8633    0.8460    0.8545      1000\n",
            "    education     0.9464    0.9350    0.9406      1000\n",
            "      science     0.8881    0.8650    0.8764      1000\n",
            "      society     0.8966    0.9190    0.9077      1000\n",
            "     politics     0.9134    0.8750    0.8938      1000\n",
            "       sports     0.9848    0.9710    0.9778      1000\n",
            "         game     0.9398    0.9360    0.9379      1000\n",
            "entertainment     0.8836    0.9640    0.9220      1000\n",
            "\n",
            "     accuracy                         0.9155     10000\n",
            "    macro avg     0.9158    0.9155    0.9154     10000\n",
            " weighted avg     0.9158    0.9155    0.9154     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[910  10  45   3   4   8   8   1   5   6]\n",
            " [ 12 934  14   2   5  12   3   4   1  13]\n",
            " [ 54  22 846   5  30   3  28   1   6   5]\n",
            " [  1   0   2 935   7  29   7   1   3  15]\n",
            " [  3   3  37   7 865  16  18   2  27  22]\n",
            " [  2  20   1  16   6 919  13   0   3  20]\n",
            " [ 15   8  27   7  19  28 875   1   3  17]\n",
            " [  2   1   1   1   3   3   4 971   0  14]\n",
            " [  2   0   5   5  31   4   1   1 936  15]\n",
            " [  1   2   2   7   4   3   1   4  12 964]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtxtgQEk0Xng",
        "outputId": "00ec458d-0c3c-424d-834b-ac0f01a385b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/drive/My\\ Drive/bao_03/02_Chinese-Text-Classification-Pytorch/run.py --model Transformer"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Vocab size: 4762\n",
            "180000it [00:02, 67803.03it/s]\n",
            "10000it [00:00, 77418.25it/s]\n",
            "10000it [00:00, 40043.23it/s]\n",
            "Time usage: 0:00:03\n",
            "<bound method Module.parameters of Model(\n",
            "  (embedding): Embedding(4762, 300)\n",
            "  (postion_embedding): Positional_Encoding(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (attention): Multi_Head_Attention(\n",
            "      (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (attention): Scaled_Dot_Product_Attention()\n",
            "      (fc): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (feed_forward): Position_wise_Feed_Forward(\n",
            "      (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (encoders): ModuleList(\n",
            "    (0): Encoder(\n",
            "      (attention): Multi_Head_Attention(\n",
            "        (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (attention): Scaled_Dot_Product_Attention()\n",
            "        (fc): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (feed_forward): Position_wise_Feed_Forward(\n",
            "        (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Encoder(\n",
            "      (attention): Multi_Head_Attention(\n",
            "        (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (attention): Scaled_Dot_Product_Attention()\n",
            "        (fc): Linear(in_features=300, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (feed_forward): Position_wise_Feed_Forward(\n",
            "        (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
            "        (dropout): Dropout(p=0.5, inplace=False)\n",
            "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc1): Linear(in_features=9600, out_features=10, bias=True)\n",
            ")>\n",
            "Epoch [1/20]\n",
            "Iter:      0,  Train Loss:   2.5,  Train Acc:  7.81%,  Val Loss:   4.5,  Val Acc: 10.00%,  Time: 0:00:01 *\n",
            "Iter:    100,  Train Loss:   1.3,  Train Acc: 54.69%,  Val Loss:   1.3,  Val Acc: 60.04%,  Time: 0:00:03 *\n",
            "Iter:    200,  Train Loss:   1.2,  Train Acc: 57.03%,  Val Loss:   1.1,  Val Acc: 67.32%,  Time: 0:00:05 *\n",
            "Iter:    300,  Train Loss:  0.87,  Train Acc: 71.88%,  Val Loss:  0.87,  Val Acc: 74.80%,  Time: 0:00:08 *\n",
            "Iter:    400,  Train Loss:  0.82,  Train Acc: 70.31%,  Val Loss:  0.73,  Val Acc: 78.14%,  Time: 0:00:10 *\n",
            "Iter:    500,  Train Loss:   0.7,  Train Acc: 81.25%,  Val Loss:  0.79,  Val Acc: 77.33%,  Time: 0:00:13 \n",
            "Iter:    600,  Train Loss:  0.65,  Train Acc: 78.12%,  Val Loss:  0.74,  Val Acc: 79.26%,  Time: 0:00:15 \n",
            "Iter:    700,  Train Loss:  0.77,  Train Acc: 71.88%,  Val Loss:  0.75,  Val Acc: 79.29%,  Time: 0:00:17 \n",
            "Iter:    800,  Train Loss:  0.58,  Train Acc: 81.25%,  Val Loss:  0.66,  Val Acc: 81.89%,  Time: 0:00:20 *\n",
            "Iter:    900,  Train Loss:  0.63,  Train Acc: 80.47%,  Val Loss:  0.65,  Val Acc: 81.62%,  Time: 0:00:22 *\n",
            "Iter:   1000,  Train Loss:   0.5,  Train Acc: 85.94%,  Val Loss:  0.66,  Val Acc: 81.49%,  Time: 0:00:24 \n",
            "Iter:   1100,  Train Loss:  0.53,  Train Acc: 82.03%,  Val Loss:  0.65,  Val Acc: 82.18%,  Time: 0:00:27 *\n",
            "Iter:   1200,  Train Loss:  0.61,  Train Acc: 78.12%,  Val Loss:  0.64,  Val Acc: 81.77%,  Time: 0:00:29 *\n",
            "Iter:   1300,  Train Loss:   0.6,  Train Acc: 80.47%,  Val Loss:  0.58,  Val Acc: 83.74%,  Time: 0:00:32 *\n",
            "Iter:   1400,  Train Loss:  0.74,  Train Acc: 75.78%,  Val Loss:   0.6,  Val Acc: 83.45%,  Time: 0:00:34 \n",
            "Epoch [2/20]\n",
            "Iter:   1500,  Train Loss:   0.6,  Train Acc: 78.91%,  Val Loss:  0.54,  Val Acc: 85.00%,  Time: 0:00:36 *\n",
            "Iter:   1600,  Train Loss:  0.44,  Train Acc: 83.59%,  Val Loss:  0.62,  Val Acc: 82.88%,  Time: 0:00:39 \n",
            "Iter:   1700,  Train Loss:  0.57,  Train Acc: 84.38%,  Val Loss:  0.56,  Val Acc: 85.40%,  Time: 0:00:41 \n",
            "Iter:   1800,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.53,  Val Acc: 85.52%,  Time: 0:00:43 *\n",
            "Iter:   1900,  Train Loss:  0.62,  Train Acc: 76.56%,  Val Loss:  0.53,  Val Acc: 85.55%,  Time: 0:00:46 *\n",
            "Iter:   2000,  Train Loss:  0.65,  Train Acc: 78.12%,  Val Loss:  0.54,  Val Acc: 85.12%,  Time: 0:00:48 \n",
            "Iter:   2100,  Train Loss:   0.6,  Train Acc: 82.81%,  Val Loss:  0.54,  Val Acc: 85.54%,  Time: 0:00:51 \n",
            "Iter:   2200,  Train Loss:  0.49,  Train Acc: 85.94%,  Val Loss:   0.5,  Val Acc: 86.75%,  Time: 0:00:53 *\n",
            "Iter:   2300,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.49,  Val Acc: 86.31%,  Time: 0:00:55 *\n",
            "Iter:   2400,  Train Loss:  0.48,  Train Acc: 85.16%,  Val Loss:  0.55,  Val Acc: 85.46%,  Time: 0:00:58 \n",
            "Iter:   2500,  Train Loss:  0.42,  Train Acc: 87.50%,  Val Loss:  0.56,  Val Acc: 85.03%,  Time: 0:01:00 \n",
            "Iter:   2600,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.54,  Val Acc: 85.58%,  Time: 0:01:03 \n",
            "Iter:   2700,  Train Loss:  0.45,  Train Acc: 89.84%,  Val Loss:  0.51,  Val Acc: 85.95%,  Time: 0:01:05 \n",
            "Iter:   2800,  Train Loss:  0.62,  Train Acc: 77.34%,  Val Loss:  0.55,  Val Acc: 84.90%,  Time: 0:01:07 \n",
            "Epoch [3/20]\n",
            "Iter:   2900,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.56,  Val Acc: 85.00%,  Time: 0:01:10 \n",
            "Iter:   3000,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.55,  Val Acc: 85.47%,  Time: 0:01:12 \n",
            "Iter:   3100,  Train Loss:  0.45,  Train Acc: 86.72%,  Val Loss:  0.57,  Val Acc: 85.08%,  Time: 0:01:14 \n",
            "Iter:   3200,  Train Loss:  0.66,  Train Acc: 82.81%,  Val Loss:  0.52,  Val Acc: 86.43%,  Time: 0:01:17 \n",
            "Iter:   3300,  Train Loss:  0.57,  Train Acc: 85.16%,  Val Loss:  0.52,  Val Acc: 86.48%,  Time: 0:01:19 \n",
            "Iter:   3400,  Train Loss:  0.53,  Train Acc: 81.25%,  Val Loss:  0.49,  Val Acc: 87.13%,  Time: 0:01:21 \n",
            "Iter:   3500,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.53,  Val Acc: 86.48%,  Time: 0:01:24 \n",
            "Iter:   3600,  Train Loss:  0.35,  Train Acc: 85.16%,  Val Loss:   0.5,  Val Acc: 86.92%,  Time: 0:01:26 \n",
            "Iter:   3700,  Train Loss:  0.58,  Train Acc: 78.91%,  Val Loss:  0.49,  Val Acc: 86.68%,  Time: 0:01:28 \n",
            "Iter:   3800,  Train Loss:  0.42,  Train Acc: 86.72%,  Val Loss:  0.52,  Val Acc: 86.14%,  Time: 0:01:31 \n",
            "Iter:   3900,  Train Loss:  0.44,  Train Acc: 85.94%,  Val Loss:  0.46,  Val Acc: 87.49%,  Time: 0:01:33 *\n",
            "Iter:   4000,  Train Loss:  0.45,  Train Acc: 88.28%,  Val Loss:  0.51,  Val Acc: 86.81%,  Time: 0:01:35 \n",
            "Iter:   4100,  Train Loss:  0.52,  Train Acc: 83.59%,  Val Loss:  0.47,  Val Acc: 87.36%,  Time: 0:01:38 \n",
            "Iter:   4200,  Train Loss:  0.54,  Train Acc: 82.81%,  Val Loss:  0.49,  Val Acc: 86.83%,  Time: 0:01:40 \n",
            "Epoch [4/20]\n",
            "Iter:   4300,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.47,  Val Acc: 87.83%,  Time: 0:01:42 \n",
            "Iter:   4400,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.48,  Val Acc: 87.48%,  Time: 0:01:45 \n",
            "Iter:   4500,  Train Loss:  0.44,  Train Acc: 87.50%,  Val Loss:  0.43,  Val Acc: 87.84%,  Time: 0:01:47 *\n",
            "Iter:   4600,  Train Loss:  0.46,  Train Acc: 83.59%,  Val Loss:  0.47,  Val Acc: 87.74%,  Time: 0:01:50 \n",
            "Iter:   4700,  Train Loss:  0.56,  Train Acc: 85.94%,  Val Loss:  0.45,  Val Acc: 87.63%,  Time: 0:01:52 \n",
            "Iter:   4800,  Train Loss:  0.31,  Train Acc: 85.94%,  Val Loss:  0.45,  Val Acc: 88.15%,  Time: 0:01:54 \n",
            "Iter:   4900,  Train Loss:   0.4,  Train Acc: 85.16%,  Val Loss:  0.45,  Val Acc: 87.51%,  Time: 0:01:57 \n",
            "Iter:   5000,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:  0.46,  Val Acc: 87.77%,  Time: 0:01:59 \n",
            "Iter:   5100,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.45,  Val Acc: 87.72%,  Time: 0:02:01 \n",
            "Iter:   5200,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.46,  Val Acc: 87.82%,  Time: 0:02:04 \n",
            "Iter:   5300,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.46,  Val Acc: 87.80%,  Time: 0:02:06 \n",
            "Iter:   5400,  Train Loss:  0.71,  Train Acc: 80.47%,  Val Loss:  0.45,  Val Acc: 87.94%,  Time: 0:02:08 \n",
            "Iter:   5500,  Train Loss:  0.41,  Train Acc: 87.50%,  Val Loss:  0.43,  Val Acc: 88.12%,  Time: 0:02:11 *\n",
            "Iter:   5600,  Train Loss:  0.39,  Train Acc: 88.28%,  Val Loss:  0.45,  Val Acc: 87.84%,  Time: 0:02:13 \n",
            "Epoch [5/20]\n",
            "Iter:   5700,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.43,  Val Acc: 88.18%,  Time: 0:02:15 *\n",
            "Iter:   5800,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.47,  Val Acc: 87.38%,  Time: 0:02:18 \n",
            "Iter:   5900,  Train Loss:  0.34,  Train Acc: 91.41%,  Val Loss:  0.43,  Val Acc: 88.01%,  Time: 0:02:20 \n",
            "Iter:   6000,  Train Loss:  0.46,  Train Acc: 82.81%,  Val Loss:  0.43,  Val Acc: 88.00%,  Time: 0:02:22 *\n",
            "Iter:   6100,  Train Loss:  0.46,  Train Acc: 88.28%,  Val Loss:  0.47,  Val Acc: 87.53%,  Time: 0:02:25 \n",
            "Iter:   6200,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.41,  Val Acc: 88.90%,  Time: 0:02:27 *\n",
            "Iter:   6300,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 88.32%,  Time: 0:02:30 \n",
            "Iter:   6400,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.43,  Val Acc: 88.32%,  Time: 0:02:32 \n",
            "Iter:   6500,  Train Loss:  0.41,  Train Acc: 88.28%,  Val Loss:  0.42,  Val Acc: 88.28%,  Time: 0:02:34 \n",
            "Iter:   6600,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.41,  Val Acc: 88.68%,  Time: 0:02:37 *\n",
            "Iter:   6700,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.41,  Val Acc: 88.14%,  Time: 0:02:39 \n",
            "Iter:   6800,  Train Loss:  0.31,  Train Acc: 88.28%,  Val Loss:  0.44,  Val Acc: 88.14%,  Time: 0:02:41 \n",
            "Iter:   6900,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 88.44%,  Time: 0:02:44 *\n",
            "Iter:   7000,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:   0.4,  Val Acc: 88.77%,  Time: 0:02:46 *\n",
            "Epoch [6/20]\n",
            "Iter:   7100,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:   0.4,  Val Acc: 88.95%,  Time: 0:02:49 \n",
            "Iter:   7200,  Train Loss:  0.51,  Train Acc: 82.03%,  Val Loss:  0.43,  Val Acc: 88.54%,  Time: 0:02:51 \n",
            "Iter:   7300,  Train Loss:  0.38,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 88.48%,  Time: 0:02:53 \n",
            "Iter:   7400,  Train Loss:   0.5,  Train Acc: 83.59%,  Val Loss:  0.44,  Val Acc: 88.29%,  Time: 0:02:56 \n",
            "Iter:   7500,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:   0.4,  Val Acc: 88.86%,  Time: 0:02:58 \n",
            "Iter:   7600,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.44,  Val Acc: 88.26%,  Time: 0:03:00 \n",
            "Iter:   7700,  Train Loss:  0.37,  Train Acc: 83.59%,  Val Loss:  0.42,  Val Acc: 88.69%,  Time: 0:03:03 \n",
            "Iter:   7800,  Train Loss:  0.44,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 87.89%,  Time: 0:03:05 \n",
            "Iter:   7900,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 88.72%,  Time: 0:03:07 *\n",
            "Iter:   8000,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 88.62%,  Time: 0:03:10 \n",
            "Iter:   8100,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:  0.42,  Val Acc: 88.23%,  Time: 0:03:12 \n",
            "Iter:   8200,  Train Loss:  0.43,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.33%,  Time: 0:03:15 *\n",
            "Iter:   8300,  Train Loss:  0.35,  Train Acc: 91.41%,  Val Loss:  0.42,  Val Acc: 88.13%,  Time: 0:03:17 \n",
            "Iter:   8400,  Train Loss:   0.6,  Train Acc: 78.91%,  Val Loss:  0.37,  Val Acc: 89.02%,  Time: 0:03:19 *\n",
            "Epoch [7/20]\n",
            "Iter:   8500,  Train Loss:  0.47,  Train Acc: 84.38%,  Val Loss:  0.44,  Val Acc: 88.03%,  Time: 0:03:22 \n",
            "Iter:   8600,  Train Loss:  0.43,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 88.52%,  Time: 0:03:24 \n",
            "Iter:   8700,  Train Loss:  0.27,  Train Acc: 92.97%,  Val Loss:   0.4,  Val Acc: 89.07%,  Time: 0:03:26 \n",
            "Iter:   8800,  Train Loss:  0.44,  Train Acc: 81.25%,  Val Loss:  0.39,  Val Acc: 88.71%,  Time: 0:03:29 \n",
            "Iter:   8900,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.41,  Val Acc: 88.65%,  Time: 0:03:31 \n",
            "Iter:   9000,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.38,  Val Acc: 89.57%,  Time: 0:03:33 \n",
            "Iter:   9100,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 89.09%,  Time: 0:03:36 \n",
            "Iter:   9200,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:   0.4,  Val Acc: 88.91%,  Time: 0:03:38 \n",
            "Iter:   9300,  Train Loss:   0.5,  Train Acc: 84.38%,  Val Loss:   0.4,  Val Acc: 88.82%,  Time: 0:03:41 \n",
            "Iter:   9400,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 88.86%,  Time: 0:03:43 \n",
            "Iter:   9500,  Train Loss:  0.25,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 89.27%,  Time: 0:03:45 \n",
            "Iter:   9600,  Train Loss:  0.49,  Train Acc: 85.16%,  Val Loss:  0.39,  Val Acc: 89.23%,  Time: 0:03:48 \n",
            "Iter:   9700,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 89.03%,  Time: 0:03:50 \n",
            "Iter:   9800,  Train Loss:  0.22,  Train Acc: 90.62%,  Val Loss:  0.39,  Val Acc: 88.34%,  Time: 0:03:52 \n",
            "Epoch [8/20]\n",
            "Iter:   9900,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.39,  Val Acc: 88.95%,  Time: 0:03:54 \n",
            "Iter:  10000,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.42,  Val Acc: 88.53%,  Time: 0:03:57 \n",
            "Iter:  10100,  Train Loss:  0.51,  Train Acc: 85.16%,  Val Loss:  0.39,  Val Acc: 89.25%,  Time: 0:03:59 \n",
            "Iter:  10200,  Train Loss:   0.4,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 89.31%,  Time: 0:04:02 \n",
            "Iter:  10300,  Train Loss:  0.41,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 89.69%,  Time: 0:04:04 \n",
            "Iter:  10400,  Train Loss:  0.34,  Train Acc: 84.38%,  Val Loss:  0.38,  Val Acc: 89.73%,  Time: 0:04:06 \n",
            "No optimization for a long time, auto-stopping...\n",
            "Test Loss:  0.36,  Test Acc: 89.15%\n",
            "Precision, Recall and F1-Score...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      finance     0.9167    0.8140    0.8623      1000\n",
            "       realty     0.9337    0.9010    0.9170      1000\n",
            "       stocks     0.7728    0.8400    0.8050      1000\n",
            "    education     0.9289    0.9400    0.9344      1000\n",
            "      science     0.8043    0.8220    0.8131      1000\n",
            "      society     0.8776    0.9180    0.8974      1000\n",
            "     politics     0.8677    0.8920    0.8797      1000\n",
            "       sports     0.9692    0.9740    0.9716      1000\n",
            "         game     0.9392    0.8810    0.9092      1000\n",
            "entertainment     0.9247    0.9330    0.9288      1000\n",
            "\n",
            "     accuracy                         0.8915     10000\n",
            "    macro avg     0.8935    0.8915    0.8918     10000\n",
            " weighted avg     0.8935    0.8915    0.8918     10000\n",
            "\n",
            "Confusion Matrix...\n",
            "[[814  18 112   7  21  14   9   2   0   3]\n",
            " [  9 901  35   3  11  16   7   4   4  10]\n",
            " [ 44  26 840   0  43   3  31   1   8   4]\n",
            " [  1   0   1 940   4  24  16   2   2  10]\n",
            " [  5   5  45  16 822  24  31   2  27  23]\n",
            " [  2   5   4  19   9 918  30   1   3   9]\n",
            " [  8   2  25   6  23  31 892   4   1   8]\n",
            " [  0   2   3   3   3   4   7 974   0   4]\n",
            " [  3   3  14   6  78   4   3   3 881   5]\n",
            " [  2   3   8  12   8   8   2  12  12 933]]\n",
            "Time usage: 0:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHuMjFiP0XtW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpaKB3JYy9KZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}