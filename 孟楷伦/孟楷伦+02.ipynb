{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0BSc_HHtpp8",
    "outputId": "28466193-925c-4984-b7ac-6b282cbadcb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (0.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 2)) (4.41.1)\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 10.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (3.12.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->-r drive/My Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt (line 3)) (50.3.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDP-8mnpt_Jk",
    "outputId": "ef0d18e4-fcfc-4d0d-9855-0c7e7e5d09ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version        \n",
      "----------------------------- ---------------\n",
      "absl-py                       0.10.0         \n",
      "alabaster                     0.7.12         \n",
      "albumentations                0.1.12         \n",
      "altair                        4.1.0          \n",
      "argon2-cffi                   20.1.0         \n",
      "asgiref                       3.2.10         \n",
      "astor                         0.8.1          \n",
      "astropy                       4.1            \n",
      "astunparse                    1.6.3          \n",
      "async-generator               1.10           \n",
      "atari-py                      0.2.6          \n",
      "atomicwrites                  1.4.0          \n",
      "attrs                         20.2.0         \n",
      "audioread                     2.1.9          \n",
      "autograd                      1.3            \n",
      "Babel                         2.8.0          \n",
      "backcall                      0.2.0          \n",
      "beautifulsoup4                4.6.3          \n",
      "bleach                        3.2.1          \n",
      "blis                          0.4.1          \n",
      "bokeh                         2.1.1          \n",
      "Bottleneck                    1.3.2          \n",
      "branca                        0.4.1          \n",
      "bs4                           0.0.1          \n",
      "CacheControl                  0.12.6         \n",
      "cachetools                    4.1.1          \n",
      "catalogue                     1.0.0          \n",
      "certifi                       2020.6.20      \n",
      "cffi                          1.14.3         \n",
      "chainer                       7.4.0          \n",
      "chardet                       3.0.4          \n",
      "click                         7.1.2          \n",
      "cloudpickle                   1.3.0          \n",
      "cmake                         3.12.0         \n",
      "cmdstanpy                     0.9.5          \n",
      "colorlover                    0.3.0          \n",
      "community                     1.0.0b1        \n",
      "contextlib2                   0.5.5          \n",
      "convertdate                   2.2.2          \n",
      "coverage                      3.7.1          \n",
      "coveralls                     0.5            \n",
      "crcmod                        1.7            \n",
      "cufflinks                     0.17.3         \n",
      "cupy-cuda101                  7.4.0          \n",
      "cvxopt                        1.2.5          \n",
      "cvxpy                         1.0.31         \n",
      "cycler                        0.10.0         \n",
      "cymem                         2.0.3          \n",
      "Cython                        0.29.21        \n",
      "daft                          0.0.4          \n",
      "dask                          2.12.0         \n",
      "dataclasses                   0.7            \n",
      "datascience                   0.10.6         \n",
      "debugpy                       1.0.0          \n",
      "decorator                     4.4.2          \n",
      "defusedxml                    0.6.0          \n",
      "descartes                     1.1.0          \n",
      "dill                          0.3.2          \n",
      "distributed                   1.25.3         \n",
      "Django                        3.1.2          \n",
      "dlib                          19.18.0        \n",
      "dm-tree                       0.1.5          \n",
      "docopt                        0.6.2          \n",
      "docutils                      0.16           \n",
      "dopamine-rl                   1.0.5          \n",
      "earthengine-api               0.1.238        \n",
      "easydict                      1.9            \n",
      "ecos                          2.0.7.post1    \n",
      "editdistance                  0.5.3          \n",
      "en-core-web-sm                2.2.5          \n",
      "entrypoints                   0.3            \n",
      "ephem                         3.7.7.1        \n",
      "et-xmlfile                    1.0.1          \n",
      "fa2                           0.3.5          \n",
      "fancyimpute                   0.4.3          \n",
      "fastai                        1.0.61         \n",
      "fastdtw                       0.3.4          \n",
      "fastprogress                  1.0.0          \n",
      "fastrlock                     0.5            \n",
      "fbprophet                     0.7.1          \n",
      "feather-format                0.4.1          \n",
      "filelock                      3.0.12         \n",
      "firebase-admin                4.4.0          \n",
      "fix-yahoo-finance             0.0.22         \n",
      "Flask                         1.1.2          \n",
      "folium                        0.8.3          \n",
      "future                        0.16.0         \n",
      "gast                          0.3.3          \n",
      "GDAL                          2.2.2          \n",
      "gdown                         3.6.4          \n",
      "gensim                        3.6.0          \n",
      "geographiclib                 1.50           \n",
      "geopy                         1.17.0         \n",
      "gin-config                    0.3.0          \n",
      "glob2                         0.7            \n",
      "google                        2.0.3          \n",
      "google-api-core               1.16.0         \n",
      "google-api-python-client      1.7.12         \n",
      "google-auth                   1.17.2         \n",
      "google-auth-httplib2          0.0.4          \n",
      "google-auth-oauthlib          0.4.1          \n",
      "google-cloud-bigquery         1.21.0         \n",
      "google-cloud-bigquery-storage 1.1.0          \n",
      "google-cloud-core             1.0.3          \n",
      "google-cloud-datastore        1.8.0          \n",
      "google-cloud-firestore        1.7.0          \n",
      "google-cloud-language         1.2.0          \n",
      "google-cloud-storage          1.18.1         \n",
      "google-cloud-translate        1.5.0          \n",
      "google-colab                  1.0.0          \n",
      "google-pasta                  0.2.0          \n",
      "google-resumable-media        0.4.1          \n",
      "googleapis-common-protos      1.52.0         \n",
      "googledrivedownloader         0.4            \n",
      "graphviz                      0.10.1         \n",
      "grpcio                        1.33.1         \n",
      "gspread                       3.0.1          \n",
      "gspread-dataframe             3.0.8          \n",
      "gym                           0.17.3         \n",
      "h5py                          2.10.0         \n",
      "HeapDict                      1.0.1          \n",
      "holidays                      0.10.3         \n",
      "holoviews                     1.13.4         \n",
      "html5lib                      1.0.1          \n",
      "httpimport                    0.5.18         \n",
      "httplib2                      0.17.4         \n",
      "httplib2shim                  0.0.3          \n",
      "humanize                      0.5.1          \n",
      "hyperopt                      0.1.2          \n",
      "ideep4py                      2.0.0.post3    \n",
      "idna                          2.10           \n",
      "image                         1.5.32         \n",
      "imageio                       2.4.1          \n",
      "imagesize                     1.2.0          \n",
      "imbalanced-learn              0.4.3          \n",
      "imblearn                      0.0            \n",
      "imgaug                        0.2.9          \n",
      "importlib-metadata            2.0.0          \n",
      "importlib-resources           3.1.0          \n",
      "imutils                       0.5.3          \n",
      "inflect                       2.1.0          \n",
      "iniconfig                     1.1.1          \n",
      "intel-openmp                  2020.0.133     \n",
      "intervaltree                  2.1.0          \n",
      "ipykernel                     4.10.1         \n",
      "ipython                       5.5.0          \n",
      "ipython-genutils              0.2.0          \n",
      "ipython-sql                   0.3.9          \n",
      "ipywidgets                    7.5.1          \n",
      "itsdangerous                  1.1.0          \n",
      "jax                           0.2.4          \n",
      "jaxlib                        0.1.56+cuda101 \n",
      "jdcal                         1.4.1          \n",
      "jedi                          0.17.2         \n",
      "jieba                         0.42.1         \n",
      "Jinja2                        2.11.2         \n",
      "joblib                        0.17.0         \n",
      "jpeg4py                       0.1.4          \n",
      "jsonschema                    2.6.0          \n",
      "jupyter                       1.0.0          \n",
      "jupyter-client                5.3.5          \n",
      "jupyter-console               5.2.0          \n",
      "jupyter-core                  4.6.3          \n",
      "jupyterlab-pygments           0.1.2          \n",
      "kaggle                        1.5.9          \n",
      "kapre                         0.1.3.1        \n",
      "Keras                         2.4.3          \n",
      "Keras-Preprocessing           1.1.2          \n",
      "keras-vis                     0.4.1          \n",
      "kiwisolver                    1.2.0          \n",
      "knnimpute                     0.1.0          \n",
      "korean-lunar-calendar         0.2.1          \n",
      "librosa                       0.6.3          \n",
      "lightgbm                      2.2.3          \n",
      "llvmlite                      0.31.0         \n",
      "lmdb                          0.99           \n",
      "lucid                         0.3.8          \n",
      "LunarCalendar                 0.0.9          \n",
      "lxml                          4.2.6          \n",
      "Markdown                      3.3.2          \n",
      "MarkupSafe                    1.1.1          \n",
      "matplotlib                    3.2.2          \n",
      "matplotlib-venn               0.11.5         \n",
      "missingno                     0.4.2          \n",
      "mistune                       0.8.4          \n",
      "mizani                        0.6.0          \n",
      "mkl                           2019.0         \n",
      "mlxtend                       0.14.0         \n",
      "more-itertools                8.5.0          \n",
      "moviepy                       0.2.3.5        \n",
      "mpmath                        1.1.0          \n",
      "msgpack                       1.0.0          \n",
      "multiprocess                  0.70.10        \n",
      "multitasking                  0.0.9          \n",
      "murmurhash                    1.0.2          \n",
      "music21                       5.5.0          \n",
      "natsort                       5.5.0          \n",
      "nbclient                      0.5.1          \n",
      "nbconvert                     5.6.1          \n",
      "nbformat                      5.0.8          \n",
      "nest-asyncio                  1.4.1          \n",
      "networkx                      2.5            \n",
      "nibabel                       3.0.2          \n",
      "nltk                          3.2.5          \n",
      "notebook                      5.3.1          \n",
      "np-utils                      0.5.12.1       \n",
      "numba                         0.48.0         \n",
      "numexpr                       2.7.1          \n",
      "numpy                         1.18.5         \n",
      "nvidia-ml-py3                 7.352.0        \n",
      "oauth2client                  4.1.3          \n",
      "oauthlib                      3.1.0          \n",
      "okgrade                       0.4.3          \n",
      "opencv-contrib-python         4.1.2.30       \n",
      "opencv-python                 4.1.2.30       \n",
      "openpyxl                      2.5.9          \n",
      "opt-einsum                    3.3.0          \n",
      "osqp                          0.6.1          \n",
      "packaging                     20.4           \n",
      "palettable                    3.3.0          \n",
      "pandas                        1.1.3          \n",
      "pandas-datareader             0.9.0          \n",
      "pandas-gbq                    0.13.3         \n",
      "pandas-profiling              1.4.1          \n",
      "pandocfilters                 1.4.2          \n",
      "panel                         0.9.7          \n",
      "param                         1.9.3          \n",
      "parso                         0.7.1          \n",
      "pathlib                       1.0.1          \n",
      "patsy                         0.5.1          \n",
      "pexpect                       4.8.0          \n",
      "pickleshare                   0.7.5          \n",
      "Pillow                        7.0.0          \n",
      "pip                           19.3.1         \n",
      "pip-tools                     4.5.1          \n",
      "plac                          1.1.3          \n",
      "plotly                        4.4.1          \n",
      "plotnine                      0.6.0          \n",
      "pluggy                        0.7.1          \n",
      "portpicker                    1.3.1          \n",
      "prefetch-generator            1.0.1          \n",
      "preshed                       3.0.2          \n",
      "prettytable                   1.0.1          \n",
      "progressbar2                  3.38.0         \n",
      "prometheus-client             0.8.0          \n",
      "promise                       2.3            \n",
      "prompt-toolkit                1.0.18         \n",
      "protobuf                      3.12.4         \n",
      "psutil                        5.4.8          \n",
      "psycopg2                      2.7.6.1        \n",
      "ptyprocess                    0.6.0          \n",
      "py                            1.9.0          \n",
      "pyarrow                       0.14.1         \n",
      "pyasn1                        0.4.8          \n",
      "pyasn1-modules                0.2.8          \n",
      "pycocotools                   2.0.2          \n",
      "pycparser                     2.20           \n",
      "pyct                          0.4.8          \n",
      "pydata-google-auth            1.1.0          \n",
      "pydot                         1.3.0          \n",
      "pydot-ng                      2.0.0          \n",
      "pydotplus                     2.0.2          \n",
      "PyDrive                       1.3.1          \n",
      "pyemd                         0.5.1          \n",
      "pyglet                        1.5.0          \n",
      "Pygments                      2.6.1          \n",
      "pygobject                     3.26.1         \n",
      "pymc3                         3.7            \n",
      "PyMeeus                       0.3.7          \n",
      "pymongo                       3.11.0         \n",
      "pymystem3                     0.2.0          \n",
      "PyOpenGL                      3.1.5          \n",
      "pyparsing                     2.4.7          \n",
      "pyrsistent                    0.17.3         \n",
      "pysndfile                     1.3.8          \n",
      "PySocks                       1.7.1          \n",
      "pystan                        2.19.1.1       \n",
      "pytest                        3.6.4          \n",
      "python-apt                    1.6.5+ubuntu0.3\n",
      "python-chess                  0.23.11        \n",
      "python-dateutil               2.8.1          \n",
      "python-louvain                0.14           \n",
      "python-slugify                4.0.1          \n",
      "python-utils                  2.4.0          \n",
      "pytz                          2018.9         \n",
      "pyviz-comms                   0.7.6          \n",
      "PyWavelets                    1.1.1          \n",
      "PyYAML                        3.13           \n",
      "pyzmq                         19.0.2         \n",
      "qtconsole                     4.7.7          \n",
      "QtPy                          1.9.0          \n",
      "regex                         2019.12.20     \n",
      "requests                      2.23.0         \n",
      "requests-oauthlib             1.3.0          \n",
      "resampy                       0.2.2          \n",
      "retrying                      1.3.3          \n",
      "rpy2                          3.2.7          \n",
      "rsa                           4.6            \n",
      "scikit-image                  0.16.2         \n",
      "scikit-learn                  0.22.2.post1   \n",
      "scipy                         1.4.1          \n",
      "screen-resolution-extra       0.0.0          \n",
      "scs                           2.1.2          \n",
      "seaborn                       0.11.0         \n",
      "Send2Trash                    1.5.0          \n",
      "setuptools                    50.3.0         \n",
      "setuptools-git                1.2            \n",
      "Shapely                       1.7.1          \n",
      "simplegeneric                 0.8.1          \n",
      "six                           1.15.0         \n",
      "sklearn                       0.0            \n",
      "sklearn-pandas                1.8.0          \n",
      "slugify                       0.0.1          \n",
      "smart-open                    3.0.0          \n",
      "snowballstemmer               2.0.0          \n",
      "sortedcontainers              2.2.2          \n",
      "spacy                         2.2.4          \n",
      "Sphinx                        1.8.5          \n",
      "sphinxcontrib-serializinghtml 1.1.4          \n",
      "sphinxcontrib-websupport      1.2.4          \n",
      "SQLAlchemy                    1.3.20         \n",
      "sqlparse                      0.4.1          \n",
      "srsly                         1.0.2          \n",
      "statsmodels                   0.10.2         \n",
      "sympy                         1.1.1          \n",
      "tables                        3.4.4          \n",
      "tabulate                      0.8.7          \n",
      "tblib                         1.7.0          \n",
      "tensorboard                   2.3.0          \n",
      "tensorboard-plugin-wit        1.7.0          \n",
      "tensorboardcolab              0.0.22         \n",
      "tensorboardX                  2.1            \n",
      "tensorflow                    2.3.0          \n",
      "tensorflow-addons             0.8.3          \n",
      "tensorflow-datasets           4.0.1          \n",
      "tensorflow-estimator          2.3.0          \n",
      "tensorflow-gcs-config         2.3.0          \n",
      "tensorflow-hub                0.9.0          \n",
      "tensorflow-metadata           0.24.0         \n",
      "tensorflow-privacy            0.2.2          \n",
      "tensorflow-probability        0.11.0         \n",
      "termcolor                     1.1.0          \n",
      "terminado                     0.9.1          \n",
      "testpath                      0.4.4          \n",
      "text-unidecode                1.3            \n",
      "textblob                      0.15.3         \n",
      "textgenrnn                    1.4.1          \n",
      "Theano                        1.0.5          \n",
      "thinc                         7.4.0          \n",
      "tifffile                      2020.9.3       \n",
      "toml                          0.10.1         \n",
      "toolz                         0.11.1         \n",
      "torch                         1.6.0+cu101    \n",
      "torchsummary                  1.5.1          \n",
      "torchtext                     0.3.1          \n",
      "torchvision                   0.7.0+cu101    \n",
      "tornado                       5.1.1          \n",
      "tqdm                          4.41.1         \n",
      "traitlets                     4.3.3          \n",
      "tweepy                        3.6.0          \n",
      "typeguard                     2.7.1          \n",
      "typing-extensions             3.7.4.3        \n",
      "tzlocal                       1.5.1          \n",
      "umap-learn                    0.4.6          \n",
      "uritemplate                   3.0.1          \n",
      "urllib3                       1.24.3         \n",
      "vega-datasets                 0.8.0          \n",
      "wasabi                        0.8.0          \n",
      "wcwidth                       0.2.5          \n",
      "webencodings                  0.5.1          \n",
      "Werkzeug                      1.0.1          \n",
      "wheel                         0.35.1         \n",
      "widgetsnbextension            3.5.1          \n",
      "wordcloud                     1.5.0          \n",
      "wrapt                         1.12.1         \n",
      "xarray                        0.15.1         \n",
      "xgboost                       0.90           \n",
      "xkit                          0.0.0          \n",
      "xlrd                          1.1.0          \n",
      "xlwt                          1.3.0          \n",
      "yellowbrick                   0.9.1          \n",
      "zict                          2.0.0          \n",
      "zipp                          3.3.1          \n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dML9-sONuG1x",
    "outputId": "0711b9f4-67fd-46b0-f1b0-4218cf55c714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 29 00:39:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxEfKcQtr__N",
    "outputId": "39024e39-c64e-4ba6-a1be-b84e619c3d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 37\n",
      "-rw------- 1 root root 1066 Oct 17 23:43 LICENSE\n",
      "drwx------ 2 root root 4096 Oct 28 14:18 models\n",
      "drwx------ 2 root root 4096 Oct 28 14:18 __pycache__\n",
      "-rw------- 1 root root 2996 Oct 17 23:43 README.md\n",
      "-rw------- 1 root root   27 Oct 28 13:45 requirements.txt\n",
      "-rw------- 1 root root 2122 Oct 28 15:15 run.py\n",
      "drwx------ 2 root root 4096 Oct 28 14:18 THUCNews\n",
      "-rw------- 1 root root 4963 Oct 17 23:43 train_eval.py\n",
      "-rw------- 1 root root 6221 Oct 17 23:43 utils_fasttext.py\n",
      "-rw------- 1 root root 5713 Oct 17 23:43 utils.py\n"
     ]
    }
   ],
   "source": [
    "# 运行linux指令\n",
    "!ls -l drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHJF9ZTluwrZ",
    "outputId": "09b99e27-5956-45f5-fe21-9c6e41cc24b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:04, 43953.38it/s]\n",
      "10000it [00:00, 15639.91it/s]\n",
      "10000it [00:00, 11750.42it/s]\n",
      "Time usage: 0:00:06\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))\n",
      "    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=768, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/20]\n",
      "Iter:      0,  Train Loss:   2.3,  Train Acc: 10.94%,  Val Loss:   2.7,  Val Acc: 12.47%,  Time: 0:00:05 *\n",
      "Iter:    100,  Train Loss:  0.76,  Train Acc: 72.66%,  Val Loss:   0.7,  Val Acc: 78.61%,  Time: 0:00:08 *\n",
      "Iter:    200,  Train Loss:   0.7,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 83.23%,  Time: 0:00:11 *\n",
      "Iter:    300,  Train Loss:  0.44,  Train Acc: 84.38%,  Val Loss:  0.49,  Val Acc: 85.07%,  Time: 0:00:14 *\n",
      "Iter:    400,  Train Loss:  0.77,  Train Acc: 79.69%,  Val Loss:  0.47,  Val Acc: 85.64%,  Time: 0:00:17 *\n",
      "Iter:    500,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.44,  Val Acc: 86.41%,  Time: 0:00:20 *\n",
      "Iter:    600,  Train Loss:  0.52,  Train Acc: 84.38%,  Val Loss:  0.44,  Val Acc: 86.55%,  Time: 0:00:23 *\n",
      "Iter:    700,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 87.33%,  Time: 0:00:26 *\n",
      "Iter:    800,  Train Loss:  0.46,  Train Acc: 86.72%,  Val Loss:  0.39,  Val Acc: 88.02%,  Time: 0:00:29 *\n",
      "Iter:    900,  Train Loss:  0.46,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 88.15%,  Time: 0:00:32 *\n",
      "Iter:   1000,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.76%,  Time: 0:00:35 \n",
      "Iter:   1100,  Train Loss:  0.38,  Train Acc: 92.97%,  Val Loss:  0.39,  Val Acc: 88.19%,  Time: 0:00:38 *\n",
      "Iter:   1200,  Train Loss:  0.36,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 88.69%,  Time: 0:00:41 *\n",
      "Iter:   1300,  Train Loss:  0.45,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 88.76%,  Time: 0:00:44 *\n",
      "Iter:   1400,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.73%,  Time: 0:00:47 *\n",
      "Epoch [2/20]\n",
      "Iter:   1500,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.77%,  Time: 0:00:50 \n",
      "Iter:   1600,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.79%,  Time: 0:00:53 *\n",
      "Iter:   1700,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.44%,  Time: 0:00:56 *\n",
      "Iter:   1800,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 88.94%,  Time: 0:00:59 \n",
      "Iter:   1900,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 89.22%,  Time: 0:01:02 \n",
      "Iter:   2000,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 89.53%,  Time: 0:01:05 *\n",
      "Iter:   2100,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.33%,  Time: 0:01:08 \n",
      "Iter:   2200,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.47%,  Time: 0:01:11 *\n",
      "Iter:   2300,  Train Loss:  0.41,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.23%,  Time: 0:01:14 \n",
      "Iter:   2400,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:01:17 \n",
      "Iter:   2500,  Train Loss:  0.16,  Train Acc: 94.53%,  Val Loss:  0.34,  Val Acc: 89.54%,  Time: 0:01:20 *\n",
      "Iter:   2600,  Train Loss:  0.38,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.95%,  Time: 0:01:23 *\n",
      "Iter:   2700,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.65%,  Time: 0:01:26 *\n",
      "Iter:   2800,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.67%,  Time: 0:01:29 \n",
      "Epoch [3/20]\n",
      "Iter:   2900,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.64%,  Time: 0:01:32 \n",
      "Iter:   3000,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.93%,  Time: 0:01:36 *\n",
      "Iter:   3100,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.51%,  Time: 0:01:39 \n",
      "Iter:   3200,  Train Loss:  0.36,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.64%,  Time: 0:01:42 \n",
      "Iter:   3300,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.78%,  Time: 0:01:45 *\n",
      "Iter:   3400,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.78%,  Time: 0:01:48 \n",
      "Iter:   3500,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 89.75%,  Time: 0:01:51 \n",
      "Iter:   3600,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.82%,  Time: 0:01:54 *\n",
      "Iter:   3700,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.96%,  Time: 0:01:57 \n",
      "Iter:   3800,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.33,  Val Acc: 89.89%,  Time: 0:02:00 \n",
      "Iter:   3900,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 90.29%,  Time: 0:02:04 *\n",
      "Iter:   4000,  Train Loss:  0.18,  Train Acc: 96.09%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:02:07 \n",
      "Iter:   4100,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.05%,  Time: 0:02:10 \n",
      "Iter:   4200,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.97%,  Time: 0:02:13 \n",
      "Epoch [4/20]\n",
      "Iter:   4300,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:02:16 \n",
      "Iter:   4400,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 90.02%,  Time: 0:02:19 \n",
      "Iter:   4500,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.12%,  Time: 0:02:22 \n",
      "Iter:   4600,  Train Loss:  0.24,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.35%,  Time: 0:02:25 \n",
      "Iter:   4700,  Train Loss:  0.33,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.50%,  Time: 0:02:29 *\n",
      "Iter:   4800,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.46%,  Time: 0:02:32 \n",
      "Iter:   4900,  Train Loss:  0.25,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 90.08%,  Time: 0:02:35 \n",
      "Iter:   5000,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 90.08%,  Time: 0:02:38 \n",
      "Iter:   5100,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.12%,  Time: 0:02:41 \n",
      "Iter:   5200,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 90.38%,  Time: 0:02:44 \n",
      "Iter:   5300,  Train Loss:  0.18,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.31%,  Time: 0:02:48 *\n",
      "Iter:   5400,  Train Loss:  0.39,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.00%,  Time: 0:02:51 \n",
      "Iter:   5500,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 90.41%,  Time: 0:02:54 \n",
      "Iter:   5600,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 90.33%,  Time: 0:02:57 \n",
      "Epoch [5/20]\n",
      "Iter:   5700,  Train Loss:  0.29,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.12%,  Time: 0:03:00 \n",
      "Iter:   5800,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.55%,  Time: 0:03:03 \n",
      "Iter:   5900,  Train Loss:  0.16,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.51%,  Time: 0:03:07 \n",
      "Iter:   6000,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.52%,  Time: 0:03:10 \n",
      "Iter:   6100,  Train Loss:  0.24,  Train Acc: 89.06%,  Val Loss:  0.33,  Val Acc: 90.28%,  Time: 0:03:13 \n",
      "Iter:   6200,  Train Loss:  0.13,  Train Acc: 97.66%,  Val Loss:  0.33,  Val Acc: 90.24%,  Time: 0:03:16 \n",
      "Iter:   6300,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 90.20%,  Time: 0:03:19 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:   0.3,  Test Acc: 90.97%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.9204    0.8670    0.8929      1000\n",
      "       realty     0.9202    0.9340    0.9270      1000\n",
      "       stocks     0.8225    0.8850    0.8526      1000\n",
      "    education     0.9419    0.9570    0.9494      1000\n",
      "      science     0.8464    0.8820    0.8639      1000\n",
      "      society     0.8968    0.9210    0.9087      1000\n",
      "     politics     0.9227    0.8710    0.8961      1000\n",
      "       sports     0.9642    0.9430    0.9535      1000\n",
      "         game     0.9457    0.9050    0.9249      1000\n",
      "entertainment     0.9292    0.9320    0.9306      1000\n",
      "\n",
      "     accuracy                         0.9097     10000\n",
      "    macro avg     0.9110    0.9097    0.9100     10000\n",
      " weighted avg     0.9110    0.9097    0.9100     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[867  17  72   6  12   9   8   4   2   3]\n",
      " [ 11 934  20   3   5  13   3   1   3   7]\n",
      " [ 35  21 885   2  31   2  17   2   3   2]\n",
      " [  1   2   2 957   4  12   7   4   1  10]\n",
      " [  5   4  36   7 882  12  15   4  29   6]\n",
      " [  3  19   3  15  16 921  14   1   3   5]\n",
      " [ 10   8  33  14  23  34 871   2   0   5]\n",
      " [  3   3   8   1   5   8   4 943   3  22]\n",
      " [  5   1  11   5  47   6   2   7 905  11]\n",
      " [  2   6   6   6  17  10   3  10   8 932]]\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBqq3KfWzRdY",
    "outputId": "a7ea8724-9074-4190-850e-c6d5911cf1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:02, 78473.45it/s]\n",
      "10000it [00:00, 83502.30it/s]\n",
      "10000it [00:00, 47805.47it/s]\n",
      "Time usage: 0:00:03\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300)\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/10]\n",
      "Iter:      0,  Train Loss:   2.3,  Train Acc:  7.81%,  Val Loss:   2.3,  Val Acc: 10.00%,  Time: 0:00:02 *\n",
      "Iter:    100,  Train Loss:   1.7,  Train Acc: 39.06%,  Val Loss:   1.6,  Val Acc: 39.53%,  Time: 0:00:04 *\n",
      "Iter:    200,  Train Loss:   1.4,  Train Acc: 45.31%,  Val Loss:   1.3,  Val Acc: 52.07%,  Time: 0:00:05 *\n",
      "Iter:    300,  Train Loss:  0.93,  Train Acc: 67.97%,  Val Loss:   1.0,  Val Acc: 65.41%,  Time: 0:00:07 *\n",
      "Iter:    400,  Train Loss:  0.72,  Train Acc: 75.00%,  Val Loss:  0.72,  Val Acc: 76.77%,  Time: 0:00:09 *\n",
      "Iter:    500,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.63,  Val Acc: 79.83%,  Time: 0:00:10 *\n",
      "Iter:    600,  Train Loss:  0.61,  Train Acc: 80.47%,  Val Loss:  0.56,  Val Acc: 82.09%,  Time: 0:00:12 *\n",
      "Iter:    700,  Train Loss:  0.51,  Train Acc: 84.38%,  Val Loss:   0.5,  Val Acc: 84.38%,  Time: 0:00:14 *\n",
      "Iter:    800,  Train Loss:  0.48,  Train Acc: 86.72%,  Val Loss:  0.48,  Val Acc: 84.87%,  Time: 0:00:15 *\n",
      "Iter:    900,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.46,  Val Acc: 85.43%,  Time: 0:00:17 *\n",
      "Iter:   1000,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:  0.45,  Val Acc: 85.47%,  Time: 0:00:19 *\n",
      "Iter:   1100,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.43,  Val Acc: 85.99%,  Time: 0:00:21 *\n",
      "Iter:   1200,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.42,  Val Acc: 86.95%,  Time: 0:00:22 *\n",
      "Iter:   1300,  Train Loss:  0.38,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 87.41%,  Time: 0:00:24 *\n",
      "Iter:   1400,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.57%,  Time: 0:00:26 *\n",
      "Epoch [2/10]\n",
      "Iter:   1500,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 87.84%,  Time: 0:00:27 *\n",
      "Iter:   1600,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:   0.4,  Val Acc: 87.46%,  Time: 0:00:29 \n",
      "Iter:   1700,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 87.10%,  Time: 0:00:31 \n",
      "Iter:   1800,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.38,  Val Acc: 88.03%,  Time: 0:00:33 \n",
      "Iter:   1900,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 88.83%,  Time: 0:00:34 *\n",
      "Iter:   2000,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 88.75%,  Time: 0:00:36 \n",
      "Iter:   2100,  Train Loss:  0.43,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 88.89%,  Time: 0:00:38 \n",
      "Iter:   2200,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.99%,  Time: 0:00:39 \n",
      "Iter:   2300,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.34%,  Time: 0:00:41 *\n",
      "Iter:   2400,  Train Loss:  0.22,  Train Acc: 94.53%,  Val Loss:  0.36,  Val Acc: 88.80%,  Time: 0:00:43 \n",
      "Iter:   2500,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.39%,  Time: 0:00:44 \n",
      "Iter:   2600,  Train Loss:  0.33,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.35%,  Time: 0:00:46 \n",
      "Iter:   2700,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.39%,  Time: 0:00:48 *\n",
      "Iter:   2800,  Train Loss:   0.4,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 89.66%,  Time: 0:00:49 *\n",
      "Epoch [3/10]\n",
      "Iter:   2900,  Train Loss:  0.38,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.46%,  Time: 0:00:51 \n",
      "Iter:   3000,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.35%,  Time: 0:00:53 \n",
      "Iter:   3100,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.28%,  Time: 0:00:55 \n",
      "Iter:   3200,  Train Loss:  0.38,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.50%,  Time: 0:00:56 \n",
      "Iter:   3300,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 89.87%,  Time: 0:00:58 *\n",
      "Iter:   3400,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.52%,  Time: 0:01:00 \n",
      "Iter:   3500,  Train Loss:  0.23,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.67%,  Time: 0:01:01 \n",
      "Iter:   3600,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.61%,  Time: 0:01:03 \n",
      "Iter:   3700,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.81%,  Time: 0:01:05 \n",
      "Iter:   3800,  Train Loss:  0.28,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.21%,  Time: 0:01:06 *\n",
      "Iter:   3900,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.16%,  Time: 0:01:08 \n",
      "Iter:   4000,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.74%,  Time: 0:01:10 \n",
      "Iter:   4100,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.18%,  Time: 0:01:12 *\n",
      "Iter:   4200,  Train Loss:  0.27,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 90.14%,  Time: 0:01:13 \n",
      "Epoch [4/10]\n",
      "Iter:   4300,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.88%,  Time: 0:01:15 \n",
      "Iter:   4400,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:17 \n",
      "Iter:   4500,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 89.89%,  Time: 0:01:18 \n",
      "Iter:   4600,  Train Loss:  0.24,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.32%,  Time: 0:01:20 *\n",
      "Iter:   4700,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.44%,  Time: 0:01:22 *\n",
      "Iter:   4800,  Train Loss:  0.11,  Train Acc: 96.09%,  Val Loss:  0.31,  Val Acc: 90.31%,  Time: 0:01:24 \n",
      "Iter:   4900,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:25 \n",
      "Iter:   5000,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.50%,  Time: 0:01:27 \n",
      "Iter:   5100,  Train Loss:  0.19,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 90.10%,  Time: 0:01:29 \n",
      "Iter:   5200,  Train Loss:   0.3,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.19%,  Time: 0:01:30 \n",
      "Iter:   5300,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.10%,  Time: 0:01:32 \n",
      "Iter:   5400,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.22%,  Time: 0:01:34 \n",
      "Iter:   5500,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.56%,  Time: 0:01:35 \n",
      "Iter:   5600,  Train Loss:  0.13,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.02%,  Time: 0:01:37 \n",
      "Epoch [5/10]\n",
      "Iter:   5700,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 90.34%,  Time: 0:01:39 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:  0.29,  Test Acc: 90.88%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.9142    0.8950    0.9045      1000\n",
      "       realty     0.9091    0.9300    0.9194      1000\n",
      "       stocks     0.8911    0.8100    0.8486      1000\n",
      "    education     0.9283    0.9580    0.9429      1000\n",
      "      science     0.8375    0.8710    0.8539      1000\n",
      "      society     0.8713    0.9340    0.9015      1000\n",
      "     politics     0.9128    0.8480    0.8792      1000\n",
      "       sports     0.9760    0.9760    0.9760      1000\n",
      "         game     0.9327    0.9290    0.9309      1000\n",
      "entertainment     0.9186    0.9370    0.9277      1000\n",
      "\n",
      "     accuracy                         0.9088     10000\n",
      "    macro avg     0.9092    0.9088    0.9085     10000\n",
      " weighted avg     0.9092    0.9088    0.9085     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[895  22  31   8  11  11  11   3   2   6]\n",
      " [  7 930  14   3   7  17   4   2   7   9]\n",
      " [ 58  31 810   5  46   6  28   2  11   3]\n",
      " [  0   0   0 958   3  20   6   0   1  12]\n",
      " [  5   5  22   9 871  25  15   1  33  14]\n",
      " [  0  16   2  16   9 934  10   0   3  10]\n",
      " [ 10   7  23  18  34  42 848   3   4  11]\n",
      " [  0   3   2   1   0   4   3 976   1  10]\n",
      " [  1   2   5   4  43   5   1   2 929   8]\n",
      " [  3   7   0  10  16   8   3  11   5 937]]\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model TextRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIeZeEpSzWFe",
    "outputId": "b7b6e829-4ba4-4c81-c5cd-d8d13bf467b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:02, 78167.20it/s]\n",
      "10000it [00:00, 81990.46it/s]\n",
      "10000it [00:00, 47689.70it/s]\n",
      "Time usage: 0:00:03\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300)\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (tanh1): Tanh()\n",
      "  (tanh2): Tanh()\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/10]\n",
      "Iter:      0,  Train Loss:   2.3,  Train Acc:  9.38%,  Val Loss:   2.3,  Val Acc: 10.28%,  Time: 0:00:00 *\n",
      "Iter:    100,  Train Loss:  0.72,  Train Acc: 75.78%,  Val Loss:  0.76,  Val Acc: 73.59%,  Time: 0:00:02 *\n",
      "Iter:    200,  Train Loss:  0.76,  Train Acc: 75.00%,  Val Loss:  0.58,  Val Acc: 81.41%,  Time: 0:00:04 *\n",
      "Iter:    300,  Train Loss:  0.39,  Train Acc: 90.62%,  Val Loss:  0.52,  Val Acc: 83.42%,  Time: 0:00:06 *\n",
      "Iter:    400,  Train Loss:  0.54,  Train Acc: 83.59%,  Val Loss:  0.48,  Val Acc: 84.55%,  Time: 0:00:08 *\n",
      "Iter:    500,  Train Loss:  0.39,  Train Acc: 89.06%,  Val Loss:  0.44,  Val Acc: 85.80%,  Time: 0:00:10 *\n",
      "Iter:    600,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.42,  Val Acc: 86.63%,  Time: 0:00:11 *\n",
      "Iter:    700,  Train Loss:   0.4,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 86.53%,  Time: 0:00:13 *\n",
      "Iter:    800,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 87.65%,  Time: 0:00:15 *\n",
      "Iter:    900,  Train Loss:  0.42,  Train Acc: 88.28%,  Val Loss:  0.37,  Val Acc: 87.92%,  Time: 0:00:17 *\n",
      "Iter:   1000,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.38,  Val Acc: 87.74%,  Time: 0:00:19 \n",
      "Iter:   1100,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.03%,  Time: 0:00:20 \n",
      "Iter:   1200,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.67%,  Time: 0:00:22 *\n",
      "Iter:   1300,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.67%,  Time: 0:00:24 \n",
      "Iter:   1400,  Train Loss:  0.42,  Train Acc: 85.94%,  Val Loss:  0.35,  Val Acc: 89.01%,  Time: 0:00:26 *\n",
      "Epoch [2/10]\n",
      "Iter:   1500,  Train Loss:  0.42,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 88.31%,  Time: 0:00:28 \n",
      "Iter:   1600,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 88.37%,  Time: 0:00:29 \n",
      "Iter:   1700,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.70%,  Time: 0:00:31 \n",
      "Iter:   1800,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 89.01%,  Time: 0:00:33 *\n",
      "Iter:   1900,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.50%,  Time: 0:00:35 *\n",
      "Iter:   2000,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.18%,  Time: 0:00:37 \n",
      "Iter:   2100,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.33,  Val Acc: 89.54%,  Time: 0:00:38 \n",
      "Iter:   2200,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.33,  Val Acc: 89.35%,  Time: 0:00:40 \n",
      "Iter:   2300,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.08%,  Time: 0:00:42 *\n",
      "Iter:   2400,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 89.13%,  Time: 0:00:44 \n",
      "Iter:   2500,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 89.83%,  Time: 0:00:46 \n",
      "Iter:   2600,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.61%,  Time: 0:00:48 \n",
      "Iter:   2700,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.16%,  Time: 0:00:49 *\n",
      "Iter:   2800,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.31,  Val Acc: 90.03%,  Time: 0:00:51 \n",
      "Epoch [3/10]\n",
      "Iter:   2900,  Train Loss:  0.33,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 89.85%,  Time: 0:00:53 \n",
      "Iter:   3000,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 89.82%,  Time: 0:00:55 \n",
      "Iter:   3100,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.32,  Val Acc: 89.71%,  Time: 0:00:57 \n",
      "Iter:   3200,  Train Loss:  0.38,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 89.58%,  Time: 0:00:58 \n",
      "Iter:   3300,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 89.97%,  Time: 0:01:00 \n",
      "Iter:   3400,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.30%,  Time: 0:01:02 \n",
      "Iter:   3500,  Train Loss:  0.15,  Train Acc: 96.09%,  Val Loss:  0.32,  Val Acc: 89.66%,  Time: 0:01:04 \n",
      "Iter:   3600,  Train Loss:  0.18,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.36%,  Time: 0:01:06 \n",
      "Iter:   3700,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.41%,  Time: 0:01:07 *\n",
      "Iter:   3800,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.00%,  Time: 0:01:09 \n",
      "Iter:   3900,  Train Loss:  0.25,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.25%,  Time: 0:01:11 \n",
      "Iter:   4000,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.32,  Val Acc: 89.97%,  Time: 0:01:13 \n",
      "Iter:   4100,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:  0.32,  Val Acc: 89.91%,  Time: 0:01:15 \n",
      "Iter:   4200,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.14%,  Time: 0:01:16 \n",
      "Epoch [4/10]\n",
      "Iter:   4300,  Train Loss:  0.18,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 90.03%,  Time: 0:01:18 \n",
      "Iter:   4400,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.31,  Val Acc: 90.40%,  Time: 0:01:20 \n",
      "Iter:   4500,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.21%,  Time: 0:01:22 \n",
      "Iter:   4600,  Train Loss:  0.18,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.38%,  Time: 0:01:24 \n",
      "Iter:   4700,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.58%,  Time: 0:01:25 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:  0.29,  Test Acc: 90.65%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.9391    0.8640    0.9000      1000\n",
      "       realty     0.9037    0.9290    0.9162      1000\n",
      "       stocks     0.8448    0.8440    0.8444      1000\n",
      "    education     0.9540    0.9340    0.9439      1000\n",
      "      science     0.8278    0.8750    0.8508      1000\n",
      "      society     0.8715    0.9360    0.9026      1000\n",
      "     politics     0.8807    0.8710    0.8758      1000\n",
      "       sports     0.9877    0.9660    0.9767      1000\n",
      "         game     0.9592    0.8930    0.9249      1000\n",
      "entertainment     0.9120    0.9530    0.9320      1000\n",
      "\n",
      "     accuracy                         0.9065     10000\n",
      "    macro avg     0.9081    0.9065    0.9067     10000\n",
      " weighted avg     0.9081    0.9065    0.9067     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[864  18  69   4  15  15   9   1   1   4]\n",
      " [  8 929  20   0   6  19   7   2   1   8]\n",
      " [ 34  31 844   3  40   4  38   0   4   2]\n",
      " [  0   4   3 934  11  18  13   1   5  11]\n",
      " [  4   9  32   8 875  16  16   1  19  20]\n",
      " [  0  14   0  15   8 936  16   0   2   9]\n",
      " [  6   8  19  10  28  45 871   1   2  10]\n",
      " [  0   3   1   1   2   7   6 966   0  14]\n",
      " [  1   6   9   1  59   8   7   2 893  14]\n",
      " [  3   6   2   3  13   6   6   4   4 953]]\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model TextRNN_Att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcV3eUqCzXEt",
    "outputId": "cc25ed31-80e5-431d-93b4-44dfcc1dff38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:02, 77033.08it/s]\n",
      "10000it [00:00, 86050.77it/s]\n",
      "10000it [00:00, 46005.46it/s]\n",
      "Time usage: 0:00:03\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.0 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300)\n",
      "  (lstm): LSTM(300, 256, batch_first=True, dropout=1.0, bidirectional=True)\n",
      "  (maxpool): MaxPool1d(kernel_size=32, stride=32, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=812, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/10]\n",
      "Iter:      0,  Train Loss:   2.6,  Train Acc:  5.47%,  Val Loss:   2.3,  Val Acc: 10.53%,  Time: 0:00:00 *\n",
      "Iter:    100,  Train Loss:  0.66,  Train Acc: 75.78%,  Val Loss:  0.72,  Val Acc: 76.47%,  Time: 0:00:02 *\n",
      "Iter:    200,  Train Loss:  0.67,  Train Acc: 78.12%,  Val Loss:  0.57,  Val Acc: 81.78%,  Time: 0:00:04 *\n",
      "Iter:    300,  Train Loss:  0.42,  Train Acc: 88.28%,  Val Loss:  0.49,  Val Acc: 84.31%,  Time: 0:00:05 *\n",
      "Iter:    400,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.47,  Val Acc: 85.08%,  Time: 0:00:07 *\n",
      "Iter:    500,  Train Loss:   0.4,  Train Acc: 89.06%,  Val Loss:  0.42,  Val Acc: 86.53%,  Time: 0:00:08 *\n",
      "Iter:    600,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.41,  Val Acc: 86.76%,  Time: 0:00:10 *\n",
      "Iter:    700,  Train Loss:  0.38,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 87.02%,  Time: 0:00:12 *\n",
      "Iter:    800,  Train Loss:  0.32,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.32%,  Time: 0:00:13 *\n",
      "Iter:    900,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 88.43%,  Time: 0:00:15 *\n",
      "Iter:   1000,  Train Loss:  0.22,  Train Acc: 92.19%,  Val Loss:  0.35,  Val Acc: 88.64%,  Time: 0:00:16 *\n",
      "Iter:   1100,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.37,  Val Acc: 87.72%,  Time: 0:00:18 \n",
      "Iter:   1200,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.85%,  Time: 0:00:20 \n",
      "Iter:   1300,  Train Loss:  0.32,  Train Acc: 86.72%,  Val Loss:  0.34,  Val Acc: 89.30%,  Time: 0:00:21 *\n",
      "Iter:   1400,  Train Loss:  0.39,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 89.04%,  Time: 0:00:23 \n",
      "Epoch [2/10]\n",
      "Iter:   1500,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.47%,  Time: 0:00:24 *\n",
      "Iter:   1600,  Train Loss:  0.28,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 89.08%,  Time: 0:00:26 \n",
      "Iter:   1700,  Train Loss:   0.3,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.41%,  Time: 0:00:28 \n",
      "Iter:   1800,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.54%,  Time: 0:00:29 *\n",
      "Iter:   1900,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.31,  Val Acc: 89.86%,  Time: 0:00:31 *\n",
      "Iter:   2000,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 90.21%,  Time: 0:00:32 *\n",
      "Iter:   2100,  Train Loss:  0.31,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 89.90%,  Time: 0:00:34 \n",
      "Iter:   2200,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:   0.3,  Val Acc: 90.05%,  Time: 0:00:36 *\n",
      "Iter:   2300,  Train Loss:  0.23,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 90.65%,  Time: 0:00:37 *\n",
      "Iter:   2400,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.33,  Val Acc: 89.64%,  Time: 0:00:39 \n",
      "Iter:   2500,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 89.99%,  Time: 0:00:40 \n",
      "Iter:   2600,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.37%,  Time: 0:00:42 \n",
      "Iter:   2700,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 90.62%,  Time: 0:00:44 \n",
      "Iter:   2800,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.30%,  Time: 0:00:45 \n",
      "Epoch [3/10]\n",
      "Iter:   2900,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:   0.3,  Val Acc: 90.41%,  Time: 0:00:47 \n",
      "Iter:   3000,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.52%,  Time: 0:00:48 \n",
      "Iter:   3100,  Train Loss:  0.16,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 89.70%,  Time: 0:00:50 \n",
      "Iter:   3200,  Train Loss:  0.31,  Train Acc: 93.75%,  Val Loss:   0.3,  Val Acc: 90.25%,  Time: 0:00:51 \n",
      "Iter:   3300,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:   0.3,  Val Acc: 90.45%,  Time: 0:00:53 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:  0.28,  Test Acc: 90.88%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.9019    0.9010    0.9015      1000\n",
      "       realty     0.9102    0.9320    0.9209      1000\n",
      "       stocks     0.8577    0.8320    0.8447      1000\n",
      "    education     0.9487    0.9430    0.9458      1000\n",
      "      science     0.8743    0.8350    0.8542      1000\n",
      "      society     0.8674    0.9290    0.8972      1000\n",
      "     politics     0.8858    0.8690    0.8773      1000\n",
      "       sports     0.9829    0.9750    0.9789      1000\n",
      "         game     0.9445    0.9190    0.9316      1000\n",
      "entertainment     0.9155    0.9530    0.9339      1000\n",
      "\n",
      "     accuracy                         0.9088     10000\n",
      "    macro avg     0.9089    0.9088    0.9086     10000\n",
      " weighted avg     0.9089    0.9088    0.9086     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[901  17  43   5   8  13   6   1   3   3]\n",
      " [ 13 932  17   0   5  19   4   1   0   9]\n",
      " [ 58  29 832   2  30   4  38   0   5   2]\n",
      " [  2   3   2 943   9  18   5   1   3  14]\n",
      " [  9   7  33   9 835  22  23   4  34  24]\n",
      " [  0  11   2  18   5 929  21   0   1  13]\n",
      " [ 10  10  28  11  16  43 869   4   2   7]\n",
      " [  0   3   1   0   1   8   3 975   0   9]\n",
      " [  2   6   9   2  40  10   4   1 919   7]\n",
      " [  4   6   3   4   6   5   8   5   6 953]]\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model TextRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WA70oL14zXtm",
    "outputId": "aa61e1ad-865b-4c8f-cf4c-3301bc32459d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:08, 21894.86it/s]\n",
      "10000it [00:00, 24462.70it/s]\n",
      "10000it [00:00, 25804.89it/s]\n",
      "Time usage: 0:00:09\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300, padding_idx=4761)\n",
      "  (embedding_ngram2): Embedding(250499, 300)\n",
      "  (embedding_ngram3): Embedding(250499, 300)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=900, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/20]\n",
      "Iter:      0,  Train Loss:   2.4,  Train Acc: 15.62%,  Val Loss:   2.3,  Val Acc:  9.37%,  Time: 0:00:03 *\n",
      "Iter:    100,  Train Loss:   1.1,  Train Acc: 62.50%,  Val Loss:   1.0,  Val Acc: 68.01%,  Time: 0:00:12 *\n",
      "Iter:    200,  Train Loss:   1.1,  Train Acc: 64.06%,  Val Loss:  0.75,  Val Acc: 76.63%,  Time: 0:00:22 *\n",
      "Iter:    300,  Train Loss:  0.71,  Train Acc: 73.44%,  Val Loss:  0.68,  Val Acc: 78.16%,  Time: 0:00:31 *\n",
      "Iter:    400,  Train Loss:  0.89,  Train Acc: 70.31%,  Val Loss:  0.67,  Val Acc: 77.42%,  Time: 0:00:45 *\n",
      "Iter:    500,  Train Loss:  0.66,  Train Acc: 80.47%,  Val Loss:  0.57,  Val Acc: 81.56%,  Time: 0:01:04 *\n",
      "Iter:    600,  Train Loss:   0.6,  Train Acc: 78.91%,  Val Loss:  0.54,  Val Acc: 82.58%,  Time: 0:01:16 *\n",
      "Iter:    700,  Train Loss:  0.76,  Train Acc: 71.88%,  Val Loss:  0.53,  Val Acc: 83.01%,  Time: 0:01:36 *\n",
      "Iter:    800,  Train Loss:  0.67,  Train Acc: 81.25%,  Val Loss:   0.5,  Val Acc: 84.04%,  Time: 0:01:46 *\n",
      "Iter:    900,  Train Loss:  0.64,  Train Acc: 81.25%,  Val Loss:  0.47,  Val Acc: 85.21%,  Time: 0:02:03 *\n",
      "Iter:   1000,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.46,  Val Acc: 85.19%,  Time: 0:02:19 *\n",
      "Iter:   1100,  Train Loss:  0.46,  Train Acc: 85.94%,  Val Loss:  0.47,  Val Acc: 85.14%,  Time: 0:02:26 \n",
      "Iter:   1200,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 86.02%,  Time: 0:02:35 *\n",
      "Iter:   1300,  Train Loss:  0.58,  Train Acc: 80.47%,  Val Loss:  0.43,  Val Acc: 86.49%,  Time: 0:02:52 *\n",
      "Iter:   1400,  Train Loss:  0.72,  Train Acc: 75.78%,  Val Loss:  0.43,  Val Acc: 86.50%,  Time: 0:03:03 *\n",
      "Epoch [2/20]\n",
      "Iter:   1500,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:  0.42,  Val Acc: 86.54%,  Time: 0:03:21 *\n",
      "Iter:   1600,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 86.69%,  Time: 0:03:33 *\n",
      "Iter:   1700,  Train Loss:  0.52,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 87.10%,  Time: 0:03:50 *\n",
      "Iter:   1800,  Train Loss:  0.37,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 87.77%,  Time: 0:04:08 *\n",
      "Iter:   1900,  Train Loss:  0.45,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 87.61%,  Time: 0:04:18 *\n",
      "Iter:   2000,  Train Loss:  0.52,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 88.06%,  Time: 0:04:38 *\n",
      "Iter:   2100,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 88.30%,  Time: 0:04:53 *\n",
      "Iter:   2200,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.37,  Val Acc: 88.61%,  Time: 0:05:04 *\n",
      "Iter:   2300,  Train Loss:  0.31,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 88.83%,  Time: 0:05:20 *\n",
      "Iter:   2400,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.81%,  Time: 0:05:26 \n",
      "Iter:   2500,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 89.23%,  Time: 0:05:36 *\n",
      "Iter:   2600,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.34,  Val Acc: 89.40%,  Time: 0:05:51 *\n",
      "Iter:   2700,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.50%,  Time: 0:06:06 *\n",
      "Iter:   2800,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.33,  Val Acc: 89.61%,  Time: 0:06:21 *\n",
      "Epoch [3/20]\n",
      "Iter:   2900,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.33,  Val Acc: 89.87%,  Time: 0:06:40 *\n",
      "Iter:   3000,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.33,  Val Acc: 89.56%,  Time: 0:06:47 \n",
      "Iter:   3100,  Train Loss:  0.33,  Train Acc: 91.41%,  Val Loss:  0.33,  Val Acc: 89.76%,  Time: 0:06:53 \n",
      "Iter:   3200,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 89.94%,  Time: 0:07:03 *\n",
      "Iter:   3300,  Train Loss:   0.4,  Train Acc: 85.16%,  Val Loss:  0.32,  Val Acc: 89.80%,  Time: 0:07:10 \n",
      "Iter:   3400,  Train Loss:  0.44,  Train Acc: 84.38%,  Val Loss:  0.33,  Val Acc: 89.94%,  Time: 0:07:16 \n",
      "Iter:   3500,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.51%,  Time: 0:07:26 *\n",
      "Iter:   3600,  Train Loss:  0.23,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.48%,  Time: 0:07:32 \n",
      "Iter:   3700,  Train Loss:  0.33,  Train Acc: 86.72%,  Val Loss:  0.31,  Val Acc: 90.57%,  Time: 0:07:42 *\n",
      "Iter:   3800,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.52%,  Time: 0:07:48 \n",
      "Iter:   3900,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 90.42%,  Time: 0:07:55 \n",
      "Iter:   4000,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.31,  Val Acc: 90.45%,  Time: 0:08:04 *\n",
      "Iter:   4100,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.62%,  Time: 0:08:14 *\n",
      "Iter:   4200,  Train Loss:  0.31,  Train Acc: 92.19%,  Val Loss:   0.3,  Val Acc: 90.55%,  Time: 0:08:23 *\n",
      "Epoch [4/20]\n",
      "Iter:   4300,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.81%,  Time: 0:08:30 \n",
      "Iter:   4400,  Train Loss:  0.17,  Train Acc: 96.09%,  Val Loss:   0.3,  Val Acc: 90.92%,  Time: 0:08:40 *\n",
      "Iter:   4500,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.29,  Val Acc: 90.99%,  Time: 0:08:49 *\n",
      "Iter:   4600,  Train Loss:  0.25,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.86%,  Time: 0:08:56 \n",
      "Iter:   4700,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.29,  Val Acc: 91.21%,  Time: 0:09:06 *\n",
      "Iter:   4800,  Train Loss:  0.17,  Train Acc: 94.53%,  Val Loss:  0.29,  Val Acc: 91.24%,  Time: 0:09:12 \n",
      "Iter:   4900,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.29,  Val Acc: 91.30%,  Time: 0:09:19 \n",
      "Iter:   5000,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.02%,  Time: 0:09:25 \n",
      "Iter:   5100,  Train Loss:  0.27,  Train Acc: 89.84%,  Val Loss:  0.29,  Val Acc: 91.41%,  Time: 0:09:35 *\n",
      "Iter:   5200,  Train Loss:  0.29,  Train Acc: 90.62%,  Val Loss:  0.28,  Val Acc: 91.40%,  Time: 0:09:44 *\n",
      "Iter:   5300,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.37%,  Time: 0:09:51 \n",
      "Iter:   5400,  Train Loss:  0.43,  Train Acc: 89.06%,  Val Loss:  0.29,  Val Acc: 91.15%,  Time: 0:09:57 \n",
      "Iter:   5500,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 91.39%,  Time: 0:10:07 *\n",
      "Iter:   5600,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.45%,  Time: 0:10:16 *\n",
      "Epoch [5/20]\n",
      "Iter:   5700,  Train Loss:  0.24,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.65%,  Time: 0:10:26 *\n",
      "Iter:   5800,  Train Loss: 0.089,  Train Acc: 97.66%,  Val Loss:  0.29,  Val Acc: 91.24%,  Time: 0:10:32 \n",
      "Iter:   5900,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.28,  Val Acc: 91.54%,  Time: 0:10:39 \n",
      "Iter:   6000,  Train Loss:  0.19,  Train Acc: 92.97%,  Val Loss:  0.28,  Val Acc: 91.31%,  Time: 0:10:45 \n",
      "Iter:   6100,  Train Loss:  0.29,  Train Acc: 92.97%,  Val Loss:  0.29,  Val Acc: 91.21%,  Time: 0:10:52 \n",
      "Iter:   6200,  Train Loss:  0.13,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 91.54%,  Time: 0:10:58 \n",
      "Iter:   6300,  Train Loss: 0.092,  Train Acc: 97.66%,  Val Loss:  0.28,  Val Acc: 91.62%,  Time: 0:11:05 \n",
      "Iter:   6400,  Train Loss: 0.047,  Train Acc: 99.22%,  Val Loss:  0.28,  Val Acc: 91.57%,  Time: 0:11:12 \n",
      "Iter:   6500,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.28,  Val Acc: 91.73%,  Time: 0:11:21 *\n",
      "Iter:   6600,  Train Loss:  0.12,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.89%,  Time: 0:11:27 \n",
      "Iter:   6700,  Train Loss:  0.11,  Train Acc: 95.31%,  Val Loss:  0.28,  Val Acc: 91.57%,  Time: 0:11:34 \n",
      "Iter:   6800,  Train Loss:  0.17,  Train Acc: 92.19%,  Val Loss:  0.28,  Val Acc: 91.68%,  Time: 0:11:40 \n",
      "Iter:   6900,  Train Loss: 0.079,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 91.60%,  Time: 0:11:47 \n",
      "Iter:   7000,  Train Loss:  0.18,  Train Acc: 94.53%,  Val Loss:  0.28,  Val Acc: 91.53%,  Time: 0:11:54 \n",
      "Epoch [6/20]\n",
      "Iter:   7100,  Train Loss: 0.086,  Train Acc: 96.88%,  Val Loss:  0.29,  Val Acc: 91.12%,  Time: 0:12:00 \n",
      "Iter:   7200,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.29,  Val Acc: 91.72%,  Time: 0:12:07 \n",
      "Iter:   7300,  Train Loss:  0.12,  Train Acc: 96.88%,  Val Loss:  0.29,  Val Acc: 91.68%,  Time: 0:12:13 \n",
      "Iter:   7400,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.29,  Val Acc: 91.24%,  Time: 0:12:20 \n",
      "Iter:   7500,  Train Loss:  0.11,  Train Acc: 95.31%,  Val Loss:  0.28,  Val Acc: 91.76%,  Time: 0:12:26 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:  0.26,  Test Acc: 91.92%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.9402    0.8810    0.9097      1000\n",
      "       realty     0.9157    0.9450    0.9301      1000\n",
      "       stocks     0.8442    0.8830    0.8631      1000\n",
      "    education     0.9614    0.9470    0.9542      1000\n",
      "      science     0.8959    0.8690    0.8822      1000\n",
      "      society     0.8840    0.9220    0.9026      1000\n",
      "     politics     0.9070    0.8880    0.8974      1000\n",
      "       sports     0.9836    0.9620    0.9727      1000\n",
      "         game     0.9389    0.9530    0.9459      1000\n",
      "entertainment     0.9281    0.9420    0.9350      1000\n",
      "\n",
      "     accuracy                         0.9192     10000\n",
      "    macro avg     0.9199    0.9192    0.9193     10000\n",
      " weighted avg     0.9199    0.9192    0.9193     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[881  13  69   2   7  12   8   2   3   3]\n",
      " [ 11 945  11   1   1  11   4   2   1  13]\n",
      " [ 33  28 883   0  23   2  22   0   6   3]\n",
      " [  1   4   2 947   5  19   9   1   3   9]\n",
      " [  3   7  32   4 869  19  18   0  34  14]\n",
      " [  2  15   3  13   8 922  20   1   5  11]\n",
      " [  4   9  34  11  13  34 888   1   1   5]\n",
      " [  0   5   3   2   4   6   5 962   0  13]\n",
      " [  0   1   7   2  28   5   1   1 953   2]\n",
      " [  2   5   2   3  12  13   4   8   9 942]]\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model FastText --embedding random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uAlypiozzYff",
    "outputId": "97db1016-22a2-4734-d46d-692c0af6b24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:02, 77833.64it/s]\n",
      "10000it [00:00, 91126.24it/s]\n",
      "10000it [00:00, 48293.38it/s]\n",
      "Time usage: 0:00:03\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300)\n",
      "  (conv_region): Conv2d(1, 250, kernel_size=(3, 300), stride=(1, 1))\n",
      "  (conv): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))\n",
      "  (max_pool): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (padding1): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)\n",
      "  (padding2): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)\n",
      "  (relu): ReLU()\n",
      "  (fc): Linear(in_features=250, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/20]\n",
      "Iter:      0,  Train Loss:   2.3,  Train Acc: 10.94%,  Val Loss:   2.8,  Val Acc:  8.06%,  Time: 0:00:00 *\n",
      "Iter:    100,  Train Loss:  0.73,  Train Acc: 74.22%,  Val Loss:  0.76,  Val Acc: 75.53%,  Time: 0:00:03 *\n",
      "Iter:    200,  Train Loss:   0.7,  Train Acc: 77.34%,  Val Loss:   0.6,  Val Acc: 80.76%,  Time: 0:00:05 *\n",
      "Iter:    300,  Train Loss:  0.45,  Train Acc: 88.28%,  Val Loss:  0.52,  Val Acc: 83.08%,  Time: 0:00:07 *\n",
      "Iter:    400,  Train Loss:  0.58,  Train Acc: 81.25%,  Val Loss:  0.51,  Val Acc: 84.13%,  Time: 0:00:09 *\n",
      "Iter:    500,  Train Loss:   0.4,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 86.33%,  Time: 0:00:11 *\n",
      "Iter:    600,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:  0.46,  Val Acc: 85.41%,  Time: 0:00:13 \n",
      "Iter:    700,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.45,  Val Acc: 85.21%,  Time: 0:00:16 \n",
      "Iter:    800,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 87.50%,  Time: 0:00:18 *\n",
      "Iter:    900,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:  0.37,  Val Acc: 88.09%,  Time: 0:00:20 *\n",
      "Iter:   1000,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 87.94%,  Time: 0:00:22 *\n",
      "Iter:   1100,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 87.27%,  Time: 0:00:25 \n",
      "Iter:   1200,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.37,  Val Acc: 88.16%,  Time: 0:00:27 \n",
      "Iter:   1300,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 89.10%,  Time: 0:00:29 *\n",
      "Iter:   1400,  Train Loss:   0.4,  Train Acc: 89.84%,  Val Loss:  0.35,  Val Acc: 88.41%,  Time: 0:00:31 \n",
      "Epoch [2/20]\n",
      "Iter:   1500,  Train Loss:  0.35,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.24%,  Time: 0:00:34 *\n",
      "Iter:   1600,  Train Loss:  0.32,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.56%,  Time: 0:00:36 \n",
      "Iter:   1700,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.34,  Val Acc: 89.29%,  Time: 0:00:38 \n",
      "Iter:   1800,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.13%,  Time: 0:00:40 \n",
      "Iter:   1900,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 89.90%,  Time: 0:00:42 *\n",
      "Iter:   2000,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.17%,  Time: 0:00:45 *\n",
      "Iter:   2100,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 90.29%,  Time: 0:00:47 *\n",
      "Iter:   2200,  Train Loss:  0.23,  Train Acc: 93.75%,  Val Loss:  0.32,  Val Acc: 90.15%,  Time: 0:00:49 \n",
      "Iter:   2300,  Train Loss:  0.21,  Train Acc: 94.53%,  Val Loss:  0.31,  Val Acc: 89.93%,  Time: 0:00:51 \n",
      "Iter:   2400,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:  0.37,  Val Acc: 88.50%,  Time: 0:00:53 \n",
      "Iter:   2500,  Train Loss:   0.2,  Train Acc: 92.97%,  Val Loss:  0.33,  Val Acc: 89.52%,  Time: 0:00:56 \n",
      "Iter:   2600,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 90.11%,  Time: 0:00:58 \n",
      "Iter:   2700,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.31,  Val Acc: 90.39%,  Time: 0:01:00 \n",
      "Iter:   2800,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.31,  Val Acc: 89.76%,  Time: 0:01:02 \n",
      "Epoch [3/20]\n",
      "Iter:   2900,  Train Loss:  0.32,  Train Acc: 89.84%,  Val Loss:  0.32,  Val Acc: 90.06%,  Time: 0:01:04 \n",
      "Iter:   3000,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:   0.3,  Val Acc: 90.71%,  Time: 0:01:06 *\n",
      "Iter:   3100,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:   0.3,  Val Acc: 90.45%,  Time: 0:01:08 \n",
      "Iter:   3200,  Train Loss:  0.43,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 89.74%,  Time: 0:01:11 \n",
      "Iter:   3300,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.71%,  Time: 0:01:13 \n",
      "Iter:   3400,  Train Loss:  0.24,  Train Acc: 91.41%,  Val Loss:   0.3,  Val Acc: 90.66%,  Time: 0:01:15 \n",
      "Iter:   3500,  Train Loss:  0.17,  Train Acc: 96.09%,  Val Loss:  0.34,  Val Acc: 89.90%,  Time: 0:01:17 \n",
      "Iter:   3600,  Train Loss: 0.097,  Train Acc: 97.66%,  Val Loss:  0.31,  Val Acc: 90.72%,  Time: 0:01:19 \n",
      "Iter:   3700,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 90.41%,  Time: 0:01:21 \n",
      "Iter:   3800,  Train Loss:  0.28,  Train Acc: 88.28%,  Val Loss:  0.31,  Val Acc: 90.48%,  Time: 0:01:23 \n",
      "Iter:   3900,  Train Loss:  0.34,  Train Acc: 89.06%,  Val Loss:  0.32,  Val Acc: 90.23%,  Time: 0:01:26 \n",
      "Iter:   4000,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.33,  Val Acc: 89.72%,  Time: 0:01:28 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:  0.28,  Test Acc: 90.89%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.8956    0.9010    0.8983      1000\n",
      "       realty     0.8843    0.9480    0.9151      1000\n",
      "       stocks     0.8651    0.8080    0.8356      1000\n",
      "    education     0.9215    0.9630    0.9418      1000\n",
      "      science     0.8533    0.8670    0.8601      1000\n",
      "      society     0.9338    0.8890    0.9109      1000\n",
      "     politics     0.8993    0.8750    0.8870      1000\n",
      "       sports     0.9749    0.9710    0.9729      1000\n",
      "         game     0.9391    0.9260    0.9325      1000\n",
      "entertainment     0.9225    0.9410    0.9317      1000\n",
      "\n",
      "     accuracy                         0.9089     10000\n",
      "    macro avg     0.9090    0.9089    0.9086     10000\n",
      " weighted avg     0.9090    0.9089    0.9086     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[901  24  45   6   7   6   7   2   1   1]\n",
      " [ 12 948  13   1   4   6   2   4   2   8]\n",
      " [ 66  37 808   6  41   2  30   1   8   1]\n",
      " [  1   3   0 963   4   8   6   1   2  12]\n",
      " [  4   6  32  14 867  14  20   0  30  13]\n",
      " [  3  23   2  21  11 889  25   3   3  20]\n",
      " [ 13  14  25  19  24  19 875   2   2   7]\n",
      " [  0   3   2   4   3   2   5 971   0  10]\n",
      " [  4   5   6   3  43   4   1   1 926   7]\n",
      " [  2   9   1   8  12   2   2  11  12 941]]\n",
      "Time usage: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model DPCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39GuPbYBzfBD",
    "outputId": "8da936d4-f4b5-4c3d-81f1-9e6a5144d81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Vocab size: 4762\n",
      "180000it [00:02, 82721.19it/s]\n",
      "10000it [00:00, 92696.31it/s]\n",
      "10000it [00:00, 48374.59it/s]\n",
      "Time usage: 0:00:02\n",
      "<bound method Module.parameters of Model(\n",
      "  (embedding): Embedding(4762, 300)\n",
      "  (postion_embedding): Positional_Encoding(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (attention): Multi_Head_Attention(\n",
      "      (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (attention): Scaled_Dot_Product_Attention()\n",
      "      (fc): Linear(in_features=300, out_features=300, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (feed_forward): Position_wise_Feed_Forward(\n",
      "      (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (attention): Multi_Head_Attention(\n",
      "        (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (attention): Scaled_Dot_Product_Attention()\n",
      "        (fc): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (feed_forward): Position_wise_Feed_Forward(\n",
      "        (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (attention): Multi_Head_Attention(\n",
      "        (fc_Q): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (fc_K): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (fc_V): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (attention): Scaled_Dot_Product_Attention()\n",
      "        (fc): Linear(in_features=300, out_features=300, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (feed_forward): Position_wise_Feed_Forward(\n",
      "        (fc1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "        (fc2): Linear(in_features=1024, out_features=300, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=9600, out_features=10, bias=True)\n",
      ")>\n",
      "Epoch [1/20]\n",
      "Iter:      0,  Train Loss:   2.4,  Train Acc: 14.06%,  Val Loss:   4.8,  Val Acc: 10.00%,  Time: 0:00:01 *\n",
      "Iter:    100,  Train Loss:   1.5,  Train Acc: 50.00%,  Val Loss:   1.9,  Val Acc: 50.01%,  Time: 0:00:04 *\n",
      "Iter:    200,  Train Loss:   1.2,  Train Acc: 58.59%,  Val Loss:   1.1,  Val Acc: 68.38%,  Time: 0:00:07 *\n",
      "Iter:    300,  Train Loss:  0.75,  Train Acc: 69.53%,  Val Loss:  0.83,  Val Acc: 74.39%,  Time: 0:00:10 *\n",
      "Iter:    400,  Train Loss:  0.95,  Train Acc: 70.31%,  Val Loss:  0.82,  Val Acc: 76.41%,  Time: 0:00:13 *\n",
      "Iter:    500,  Train Loss:  0.88,  Train Acc: 70.31%,  Val Loss:  0.86,  Val Acc: 75.93%,  Time: 0:00:17 \n",
      "Iter:    600,  Train Loss:  0.85,  Train Acc: 75.78%,  Val Loss:  0.75,  Val Acc: 79.29%,  Time: 0:00:20 *\n",
      "Iter:    700,  Train Loss:  0.67,  Train Acc: 75.78%,  Val Loss:  0.79,  Val Acc: 79.42%,  Time: 0:00:23 \n",
      "Iter:    800,  Train Loss:  0.59,  Train Acc: 83.59%,  Val Loss:  0.66,  Val Acc: 81.54%,  Time: 0:00:26 *\n",
      "Iter:    900,  Train Loss:  0.63,  Train Acc: 79.69%,  Val Loss:  0.62,  Val Acc: 82.39%,  Time: 0:00:29 *\n",
      "Iter:   1000,  Train Loss:  0.55,  Train Acc: 80.47%,  Val Loss:  0.64,  Val Acc: 82.08%,  Time: 0:00:33 \n",
      "Iter:   1100,  Train Loss:  0.51,  Train Acc: 77.34%,  Val Loss:  0.63,  Val Acc: 82.40%,  Time: 0:00:36 \n",
      "Iter:   1200,  Train Loss:  0.55,  Train Acc: 81.25%,  Val Loss:   0.6,  Val Acc: 83.28%,  Time: 0:00:39 *\n",
      "Iter:   1300,  Train Loss:  0.65,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 84.57%,  Time: 0:00:42 *\n",
      "Iter:   1400,  Train Loss:  0.73,  Train Acc: 78.12%,  Val Loss:  0.61,  Val Acc: 83.33%,  Time: 0:00:45 \n",
      "Epoch [2/20]\n",
      "Iter:   1500,  Train Loss:  0.59,  Train Acc: 80.47%,  Val Loss:  0.53,  Val Acc: 85.14%,  Time: 0:00:48 *\n",
      "Iter:   1600,  Train Loss:  0.51,  Train Acc: 79.69%,  Val Loss:  0.61,  Val Acc: 83.83%,  Time: 0:00:51 \n",
      "Iter:   1700,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.59,  Val Acc: 84.30%,  Time: 0:00:54 \n",
      "Iter:   1800,  Train Loss:  0.38,  Train Acc: 88.28%,  Val Loss:  0.54,  Val Acc: 86.05%,  Time: 0:00:58 \n",
      "Iter:   1900,  Train Loss:  0.48,  Train Acc: 82.03%,  Val Loss:  0.52,  Val Acc: 85.64%,  Time: 0:01:01 *\n",
      "Iter:   2000,  Train Loss:  0.57,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 85.14%,  Time: 0:01:04 \n",
      "Iter:   2100,  Train Loss:   0.6,  Train Acc: 79.69%,  Val Loss:  0.56,  Val Acc: 84.96%,  Time: 0:01:07 \n",
      "Iter:   2200,  Train Loss:  0.41,  Train Acc: 85.16%,  Val Loss:  0.54,  Val Acc: 85.73%,  Time: 0:01:10 \n",
      "Iter:   2300,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.51,  Val Acc: 85.55%,  Time: 0:01:13 *\n",
      "Iter:   2400,  Train Loss:  0.58,  Train Acc: 82.03%,  Val Loss:  0.55,  Val Acc: 85.77%,  Time: 0:01:16 \n",
      "Iter:   2500,  Train Loss:  0.53,  Train Acc: 78.91%,  Val Loss:  0.55,  Val Acc: 84.86%,  Time: 0:01:19 \n",
      "Iter:   2600,  Train Loss:  0.47,  Train Acc: 84.38%,  Val Loss:  0.51,  Val Acc: 86.02%,  Time: 0:01:22 \n",
      "Iter:   2700,  Train Loss:  0.45,  Train Acc: 87.50%,  Val Loss:  0.51,  Val Acc: 85.83%,  Time: 0:01:25 \n",
      "Iter:   2800,  Train Loss:   0.6,  Train Acc: 80.47%,  Val Loss:  0.48,  Val Acc: 86.34%,  Time: 0:01:28 *\n",
      "Epoch [3/20]\n",
      "Iter:   2900,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.53,  Val Acc: 85.48%,  Time: 0:01:31 \n",
      "Iter:   3000,  Train Loss:   0.4,  Train Acc: 86.72%,  Val Loss:  0.51,  Val Acc: 86.63%,  Time: 0:01:34 \n",
      "Iter:   3100,  Train Loss:   0.5,  Train Acc: 85.94%,  Val Loss:   0.5,  Val Acc: 86.42%,  Time: 0:01:38 \n",
      "Iter:   3200,  Train Loss:  0.59,  Train Acc: 83.59%,  Val Loss:  0.52,  Val Acc: 86.12%,  Time: 0:01:41 \n",
      "Iter:   3300,  Train Loss:   0.5,  Train Acc: 85.94%,  Val Loss:  0.47,  Val Acc: 87.50%,  Time: 0:01:44 *\n",
      "Iter:   3400,  Train Loss:  0.49,  Train Acc: 83.59%,  Val Loss:  0.49,  Val Acc: 87.43%,  Time: 0:01:47 \n",
      "Iter:   3500,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.53,  Val Acc: 86.34%,  Time: 0:01:50 \n",
      "Iter:   3600,  Train Loss:   0.4,  Train Acc: 85.16%,  Val Loss:   0.5,  Val Acc: 86.26%,  Time: 0:01:53 \n",
      "Iter:   3700,  Train Loss:  0.63,  Train Acc: 79.69%,  Val Loss:  0.47,  Val Acc: 87.10%,  Time: 0:01:56 *\n",
      "Iter:   3800,  Train Loss:  0.43,  Train Acc: 86.72%,  Val Loss:  0.52,  Val Acc: 85.86%,  Time: 0:01:59 \n",
      "Iter:   3900,  Train Loss:  0.48,  Train Acc: 84.38%,  Val Loss:  0.48,  Val Acc: 86.83%,  Time: 0:02:02 \n",
      "Iter:   4000,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:   0.5,  Val Acc: 86.79%,  Time: 0:02:05 \n",
      "Iter:   4100,  Train Loss:  0.46,  Train Acc: 81.25%,  Val Loss:  0.45,  Val Acc: 86.67%,  Time: 0:02:09 *\n",
      "Iter:   4200,  Train Loss:  0.52,  Train Acc: 81.25%,  Val Loss:  0.49,  Val Acc: 87.14%,  Time: 0:02:12 \n",
      "Epoch [4/20]\n",
      "Iter:   4300,  Train Loss:  0.41,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 88.28%,  Time: 0:02:15 *\n",
      "Iter:   4400,  Train Loss:  0.26,  Train Acc: 92.97%,  Val Loss:  0.46,  Val Acc: 87.66%,  Time: 0:02:18 \n",
      "Iter:   4500,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.45,  Val Acc: 87.79%,  Time: 0:02:21 \n",
      "Iter:   4600,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.44,  Val Acc: 88.00%,  Time: 0:02:24 \n",
      "Iter:   4700,  Train Loss:  0.58,  Train Acc: 80.47%,  Val Loss:  0.44,  Val Acc: 87.57%,  Time: 0:02:27 \n",
      "Iter:   4800,  Train Loss:  0.35,  Train Acc: 86.72%,  Val Loss:  0.47,  Val Acc: 87.78%,  Time: 0:02:30 \n",
      "Iter:   4900,  Train Loss:  0.39,  Train Acc: 85.16%,  Val Loss:  0.46,  Val Acc: 87.58%,  Time: 0:02:33 \n",
      "Iter:   5000,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:  0.47,  Val Acc: 87.70%,  Time: 0:02:36 \n",
      "Iter:   5100,  Train Loss:  0.51,  Train Acc: 83.59%,  Val Loss:  0.43,  Val Acc: 87.74%,  Time: 0:02:39 *\n",
      "Iter:   5200,  Train Loss:  0.55,  Train Acc: 80.47%,  Val Loss:  0.45,  Val Acc: 87.21%,  Time: 0:02:43 \n",
      "Iter:   5300,  Train Loss:  0.35,  Train Acc: 89.84%,  Val Loss:  0.49,  Val Acc: 86.89%,  Time: 0:02:46 \n",
      "Iter:   5400,  Train Loss:  0.72,  Train Acc: 81.25%,  Val Loss:  0.43,  Val Acc: 88.03%,  Time: 0:02:49 \n",
      "Iter:   5500,  Train Loss:  0.36,  Train Acc: 86.72%,  Val Loss:  0.43,  Val Acc: 87.90%,  Time: 0:02:52 \n",
      "Iter:   5600,  Train Loss:  0.43,  Train Acc: 85.16%,  Val Loss:  0.48,  Val Acc: 87.17%,  Time: 0:02:55 \n",
      "Epoch [5/20]\n",
      "Iter:   5700,  Train Loss:  0.43,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 87.99%,  Time: 0:02:58 *\n",
      "Iter:   5800,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:  0.45,  Val Acc: 87.83%,  Time: 0:03:01 \n",
      "Iter:   5900,  Train Loss:  0.37,  Train Acc: 85.16%,  Val Loss:  0.41,  Val Acc: 88.35%,  Time: 0:03:04 *\n",
      "Iter:   6000,  Train Loss:   0.5,  Train Acc: 83.59%,  Val Loss:  0.43,  Val Acc: 88.18%,  Time: 0:03:07 \n",
      "Iter:   6100,  Train Loss:  0.48,  Train Acc: 83.59%,  Val Loss:  0.43,  Val Acc: 88.50%,  Time: 0:03:10 \n",
      "Iter:   6200,  Train Loss:  0.27,  Train Acc: 93.75%,  Val Loss:  0.43,  Val Acc: 88.59%,  Time: 0:03:13 \n",
      "Iter:   6300,  Train Loss:  0.41,  Train Acc: 85.94%,  Val Loss:  0.44,  Val Acc: 87.82%,  Time: 0:03:16 \n",
      "Iter:   6400,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.41,  Val Acc: 88.49%,  Time: 0:03:19 \n",
      "Iter:   6500,  Train Loss:  0.54,  Train Acc: 87.50%,  Val Loss:  0.44,  Val Acc: 87.93%,  Time: 0:03:22 \n",
      "Iter:   6600,  Train Loss:  0.43,  Train Acc: 88.28%,  Val Loss:  0.41,  Val Acc: 88.78%,  Time: 0:03:26 \n",
      "Iter:   6700,  Train Loss:  0.33,  Train Acc: 88.28%,  Val Loss:  0.41,  Val Acc: 88.19%,  Time: 0:03:29 \n",
      "Iter:   6800,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.45,  Val Acc: 88.34%,  Time: 0:03:32 \n",
      "Iter:   6900,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:  0.42,  Val Acc: 88.18%,  Time: 0:03:35 \n",
      "Iter:   7000,  Train Loss:  0.44,  Train Acc: 85.16%,  Val Loss:  0.45,  Val Acc: 87.17%,  Time: 0:03:38 \n",
      "Epoch [6/20]\n",
      "Iter:   7100,  Train Loss:  0.35,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 89.11%,  Time: 0:03:41 *\n",
      "Iter:   7200,  Train Loss:   0.4,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 88.82%,  Time: 0:03:44 \n",
      "Iter:   7300,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.20%,  Time: 0:03:47 *\n",
      "Iter:   7400,  Train Loss:  0.54,  Train Acc: 84.38%,  Val Loss:  0.43,  Val Acc: 88.53%,  Time: 0:03:50 \n",
      "Iter:   7500,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 88.79%,  Time: 0:03:53 \n",
      "Iter:   7600,  Train Loss:  0.32,  Train Acc: 89.06%,  Val Loss:  0.43,  Val Acc: 87.94%,  Time: 0:03:56 \n",
      "Iter:   7700,  Train Loss:  0.42,  Train Acc: 85.16%,  Val Loss:  0.42,  Val Acc: 88.60%,  Time: 0:03:59 \n",
      "Iter:   7800,  Train Loss:  0.47,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 88.59%,  Time: 0:04:02 \n",
      "Iter:   7900,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:   0.4,  Val Acc: 88.62%,  Time: 0:04:05 \n",
      "Iter:   8000,  Train Loss:  0.42,  Train Acc: 89.06%,  Val Loss:  0.42,  Val Acc: 88.31%,  Time: 0:04:08 \n",
      "Iter:   8100,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:   0.4,  Val Acc: 88.62%,  Time: 0:04:12 \n",
      "Iter:   8200,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 88.60%,  Time: 0:04:15 \n",
      "Iter:   8300,  Train Loss:  0.25,  Train Acc: 94.53%,  Val Loss:  0.42,  Val Acc: 88.07%,  Time: 0:04:18 \n",
      "Iter:   8400,  Train Loss:   0.6,  Train Acc: 78.91%,  Val Loss:  0.37,  Val Acc: 88.87%,  Time: 0:04:21 *\n",
      "Epoch [7/20]\n",
      "Iter:   8500,  Train Loss:  0.52,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 88.86%,  Time: 0:04:24 \n",
      "Iter:   8600,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.43,  Val Acc: 88.47%,  Time: 0:04:27 \n",
      "Iter:   8700,  Train Loss:  0.33,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 89.27%,  Time: 0:04:30 \n",
      "Iter:   8800,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:   0.4,  Val Acc: 88.87%,  Time: 0:04:33 \n",
      "Iter:   8900,  Train Loss:  0.36,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 89.33%,  Time: 0:04:36 \n",
      "Iter:   9000,  Train Loss:  0.21,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 89.35%,  Time: 0:04:39 \n",
      "Iter:   9100,  Train Loss:  0.45,  Train Acc: 89.06%,  Val Loss:   0.4,  Val Acc: 89.13%,  Time: 0:04:42 \n",
      "Iter:   9200,  Train Loss:  0.47,  Train Acc: 85.16%,  Val Loss:   0.4,  Val Acc: 88.98%,  Time: 0:04:45 \n",
      "Iter:   9300,  Train Loss:  0.51,  Train Acc: 79.69%,  Val Loss:  0.37,  Val Acc: 89.13%,  Time: 0:04:48 *\n",
      "Iter:   9400,  Train Loss:  0.54,  Train Acc: 82.81%,  Val Loss:  0.41,  Val Acc: 88.70%,  Time: 0:04:51 \n",
      "Iter:   9500,  Train Loss:   0.3,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 89.28%,  Time: 0:04:54 \n",
      "Iter:   9600,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.39,  Val Acc: 89.32%,  Time: 0:04:57 \n",
      "Iter:   9700,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.39,  Val Acc: 89.04%,  Time: 0:05:00 \n",
      "Iter:   9800,  Train Loss:  0.34,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 88.86%,  Time: 0:05:04 \n",
      "Epoch [8/20]\n",
      "Iter:   9900,  Train Loss:  0.58,  Train Acc: 82.03%,  Val Loss:  0.38,  Val Acc: 89.48%,  Time: 0:05:07 \n",
      "Iter:  10000,  Train Loss:  0.27,  Train Acc: 90.62%,  Val Loss:  0.41,  Val Acc: 88.88%,  Time: 0:05:10 \n",
      "Iter:  10100,  Train Loss:  0.53,  Train Acc: 83.59%,  Val Loss:   0.4,  Val Acc: 89.13%,  Time: 0:05:13 \n",
      "Iter:  10200,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 89.22%,  Time: 0:05:16 \n",
      "Iter:  10300,  Train Loss:  0.39,  Train Acc: 89.84%,  Val Loss:  0.38,  Val Acc: 89.54%,  Time: 0:05:19 \n",
      "Iter:  10400,  Train Loss:  0.34,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 89.16%,  Time: 0:05:22 \n",
      "Iter:  10500,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:   0.4,  Val Acc: 89.18%,  Time: 0:05:25 \n",
      "Iter:  10600,  Train Loss:  0.39,  Train Acc: 86.72%,  Val Loss:  0.39,  Val Acc: 89.29%,  Time: 0:05:28 \n",
      "Iter:  10700,  Train Loss:  0.28,  Train Acc: 91.41%,  Val Loss:  0.39,  Val Acc: 88.76%,  Time: 0:05:31 \n",
      "Iter:  10800,  Train Loss:  0.42,  Train Acc: 85.94%,  Val Loss:  0.39,  Val Acc: 89.18%,  Time: 0:05:34 \n",
      "Iter:  10900,  Train Loss:  0.48,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 89.39%,  Time: 0:05:37 \n",
      "Iter:  11000,  Train Loss:  0.36,  Train Acc: 88.28%,  Val Loss:  0.39,  Val Acc: 89.01%,  Time: 0:05:40 \n",
      "Iter:  11100,  Train Loss:  0.37,  Train Acc: 90.62%,  Val Loss:  0.38,  Val Acc: 88.99%,  Time: 0:05:43 \n",
      "Iter:  11200,  Train Loss:  0.42,  Train Acc: 83.59%,  Val Loss:  0.39,  Val Acc: 89.17%,  Time: 0:05:46 \n",
      "Epoch [9/20]\n",
      "Iter:  11300,  Train Loss:  0.38,  Train Acc: 87.50%,  Val Loss:  0.39,  Val Acc: 89.43%,  Time: 0:05:49 \n",
      "No optimization for a long time, auto-stopping...\n",
      "Test Loss:  0.36,  Test Acc: 89.14%\n",
      "Precision, Recall and F1-Score...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      finance     0.8542    0.8850    0.8694      1000\n",
      "       realty     0.8971    0.9240    0.9103      1000\n",
      "       stocks     0.8554    0.7570    0.8032      1000\n",
      "    education     0.9171    0.9510    0.9337      1000\n",
      "      science     0.8426    0.7920    0.8165      1000\n",
      "      society     0.9195    0.8800    0.8993      1000\n",
      "     politics     0.8426    0.8940    0.8675      1000\n",
      "       sports     0.9867    0.9620    0.9742      1000\n",
      "         game     0.9085    0.9140    0.9113      1000\n",
      "entertainment     0.8900    0.9550    0.9214      1000\n",
      "\n",
      "     accuracy                         0.8914     10000\n",
      "    macro avg     0.8914    0.8914    0.8907     10000\n",
      " weighted avg     0.8914    0.8914    0.8907     10000\n",
      "\n",
      "Confusion Matrix...\n",
      "[[885  27  44   9  14   2  12   1   3   3]\n",
      " [ 14 924  19   4   6  11   6   1   1  14]\n",
      " [ 91  30 757   2  47   0  51   1  14   7]\n",
      " [  3   4   1 951   6   8   7   1   5  14]\n",
      " [ 16  11  33  12 792  21  36   1  47  31]\n",
      " [  4  19   2  28   7 880  38   0   5  17]\n",
      " [ 14   6  18  15   9  23 894   1   5  15]\n",
      " [  0   2   2   4   6   3   7 962   0  14]\n",
      " [  4   4   8   7  45   5   8   2 914   3]\n",
      " [  5   3   1   5   8   4   2   5  12 955]]\n",
      "Time usage: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "!python drive/My\\ Drive/NLP_1_test/02_Chinese-Text-Classification-Pytorch/run.py --model Transformer"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test_2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
